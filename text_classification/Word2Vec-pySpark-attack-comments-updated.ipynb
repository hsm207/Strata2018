{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Notice\" data-toc-modified-id=\"Notice-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Notice</a></span></li><li><span><a href=\"#Creating-word-vectors-using-word2vec:-implementation-in-Spark-MLlib\" data-toc-modified-id=\"Creating-word-vectors-using-word2vec:-implementation-in-Spark-MLlib-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Creating word vectors using word2vec: implementation in Spark MLlib</a></span><ul class=\"toc-item\"><li><span><a href=\"#PREPARE-DATA:-Download-data-and-create-input-output-directories\" data-toc-modified-id=\"PREPARE-DATA:-Download-data-and-create-input-output-directories-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>PREPARE DATA: Download data and create input output directories</a></span><ul class=\"toc-item\"><li><span><a href=\"#Here-we-show-how-to-use-Spark-MLlib-Word2Vec-for-generating-word-features\" data-toc-modified-id=\"Here-we-show-how-to-use-Spark-MLlib-Word2Vec-for-generating-word-features-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Here we show how to use Spark MLlib Word2Vec for generating word-features</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-data-being-used-is-the-attack-comments-text-data\" data-toc-modified-id=\"The-data-being-used-is-the-attack-comments-text-data-2.1.1.1\"><span class=\"toc-item-num\">2.1.1.1&nbsp;&nbsp;</span>The data being used is the attack comments text data</a></span></li></ul></li></ul></li><li><span><a href=\"#Set-directory-path-for-input-data\" data-toc-modified-id=\"Set-directory-path-for-input-data-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Set directory path for input data</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Input-data-is-downloaded-locally-to-a-DSVM\" data-toc-modified-id=\"Input-data-is-downloaded-locally-to-a-DSVM-2.2.0.1\"><span class=\"toc-item-num\">2.2.0.1&nbsp;&nbsp;</span>Input data is downloaded locally to a DSVM</a></span></li></ul></li></ul></li><li><span><a href=\"#Set-spark-context-and-import-necessary-libraries\" data-toc-modified-id=\"Set-spark-context-and-import-necessary-libraries-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Set spark context and import necessary libraries</a></span></li><li><span><a href=\"#Data-ingestion:-Read-in-attack-text-data-from-.csv-file\" data-toc-modified-id=\"Data-ingestion:-Read-in-attack-text-data-from-.csv-file-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Data ingestion: Read in attack text data from .csv file</a></span></li><li><span><a href=\"#Select-and-filter-data-set-(only-training-articles)\" data-toc-modified-id=\"Select-and-filter-data-set-(only-training-articles)-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Select and filter data set (only training articles)</a></span></li><li><span><a href=\"#Lowercase-COMMENT-and-remove-some-irrelevant-words-and-punctuations\" data-toc-modified-id=\"Lowercase-COMMENT-and-remove-some-irrelevant-words-and-punctuations-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Lowercase COMMENT and remove some irrelevant words and punctuations</a></span></li><li><span><a href=\"#Tokenize-COMMENT-and-remove-stopwords\" data-toc-modified-id=\"Tokenize-COMMENT-and-remove-stopwords-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Tokenize COMMENT and remove stopwords</a></span></li><li><span><a href=\"#DEFINE-AND-RUN-WORD2VEC-ON-COMMENTS\" data-toc-modified-id=\"DEFINE-AND-RUN-WORD2VEC-ON-COMMENTS-2.8\"><span class=\"toc-item-num\">2.8&nbsp;&nbsp;</span>DEFINE AND RUN WORD2VEC ON COMMENTS</a></span></li><li><span><a href=\"#Examine-some-words,-and-other-words-close-to-them-from-these-feature-neighborhood\" data-toc-modified-id=\"Examine-some-words,-and-other-words-close-to-them-from-these-feature-neighborhood-2.9\"><span class=\"toc-item-num\">2.9&nbsp;&nbsp;</span>Examine some words, and other words close to them from these feature neighborhood</a></span></li><li><span><a href=\"#Examine-how-the-vector-features-look-like\" data-toc-modified-id=\"Examine-how-the-vector-features-look-like-2.10\"><span class=\"toc-item-num\">2.10&nbsp;&nbsp;</span>Examine how the vector features look like</a></span></li><li><span><a href=\"#Convert-Spark-DF-to-Pandas-DF-for-output-into-a-CSV-file\" data-toc-modified-id=\"Convert-Spark-DF-to-Pandas-DF-for-output-into-a-CSV-file-2.11\"><span class=\"toc-item-num\">2.11&nbsp;&nbsp;</span>Convert Spark DF to Pandas DF for output into a CSV file</a></span></li><li><span><a href=\"#Get-comment-level-vectors-from-word-level-vectors-(averaging)\" data-toc-modified-id=\"Get-comment-level-vectors-from-word-level-vectors-(averaging)-2.12\"><span class=\"toc-item-num\">2.12&nbsp;&nbsp;</span>Get comment-level vectors from word-level vectors (averaging)</a></span></li><li><span><a href=\"#SAVE-FEATURES-in-CSV-file-for-subsequent-steps\" data-toc-modified-id=\"SAVE-FEATURES-in-CSV-file-for-subsequent-steps-2.13\"><span class=\"toc-item-num\">2.13&nbsp;&nbsp;</span>SAVE FEATURES in CSV file for subsequent steps</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebok was run on a local computer connected to a databricks cluster using Databricks Connect.\n",
    "\n",
    "Click [here](https://docs.databricks.com/user-guide/dev-tools/db-connect.html) for instructions on how to setup Databricks Connect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating word vectors using word2vec: implementation in Spark MLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPARE DATA: Download data and create input output directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we show how to use Spark MLlib Word2Vec for generating word-features \n",
    "#### The data being used is the attack comments text data\n",
    "\n",
    "This notebook will take take about 1-2 mins to finish on a Python 3 Spark kernel on a DSVM with Spark\n",
    "\n",
    "MLlib Word2Vec: https://spark.apache.org/docs/2.2.0/mllib-feature-extraction.html#word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set directory path for input data \n",
    "#### Input data is downloaded locally to a DSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and unzip the data from this link:\n",
    "\n",
    "https://activelearnwestus.blob.core.windows.net/activelearningdemo/text_data.zip\n",
    "\n",
    "Then, upload the data to somewhere in dbfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this path to where you store the unzipped data files\n",
    "text_file = '/msh/attack_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Location of training data on \n",
    "# text_file = \"./text_data/attack_data.csv\"\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "# my_file = Path(text_file)\n",
    "\n",
    "# download_file = 1\n",
    "# if my_file.exists():\n",
    "#     download_file = 0\n",
    "\n",
    "# if download_file == 1:\n",
    "#     !wget https://activelearning.blob.core.windows.net/activelearningdemo/text_data.zip\n",
    "#     !unzip text_data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set spark context and import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext, SparkSession, DataFrame, SparkSession\n",
    "from pyspark.sql.functions import UserDefinedFunction, regexp_replace, trim, col, lower, lit, udf, monotonically_increasing_id\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import Word2Vec, Word2VecModel, Tokenizer, RegexTokenizer, StopWordsRemover\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data ingestion: Read in attack text data from .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115864"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## READ IN DATA AND CREATE SPARK DATAFRAME FROM A CSV & AND MATERIALIZE IN MEMORY\n",
    "text_df = spark.read.csv(path=text_file, header=True, inferSchema=True, sep=\",\")\n",
    "text_df.cache();\n",
    "\n",
    "## REGISTER DATA-FRAME AS A TEMP-TABLE IN SQL-CONTEXT\n",
    "text_df.createOrReplaceTempView(\"text_table\")\n",
    "\n",
    "# COUNT NUMBER OF ROWS IN DATA FRAME\n",
    "text_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>count</th>\n",
       "      <th>avg_attack</th>\n",
       "      <th>is_attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>`-NEWLINE_TOKENThis is not ``creative``.  Thos...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id                                            comment  year logged_in  \\\n",
       "0   37675  `-NEWLINE_TOKENThis is not ``creative``.  Thos...  2002     False   \n",
       "\n",
       "        ns  sample  split count  avg_attack  is_attack  \n",
       "0  article  random  train    10         0.0      False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SELECT ONE ROW FROM THE SPARK DATAFRAME\n",
    "text_df.limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ns</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>article</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>article</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>article</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>user</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ns  split\n",
       "0  article    dev\n",
       "1  article   test\n",
       "2  article  train\n",
       "3     user    dev\n",
       "4     user   test\n",
       "5     user  train"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### SELECT A FEW COLUMNS BASED ON WHICH WE FILTER\n",
    "sqlStatement = \"\"\" SELECT distinct ns, split \n",
    "            FROM text_table \n",
    "            where split in ('train', 'test', 'dev') \n",
    "            order by ns, split \"\"\"\n",
    "spark.sql(sqlStatement).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View some example comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24778596\n",
      "False\n",
      "NEWLINE_TOKEN::It's good to have more than one set of eyeballs looking over everything.\n",
      "\n",
      "\n",
      "30793313\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKENAlso, that whole paragraph is full of spelling and grammatical errors, and is rather badly written as well.\n",
      "\n",
      "\n",
      "34730891\n",
      "False\n",
      "`NEWLINE_TOKENNEWLINE_TOKEN>> I do not think Mongo, or anyone else here, is qualified to judge the reputation of a spource.\\NEWLINE_TOKENAlso, it you want this article to be old,old, and stuffy,  limited, then ask for ``mainstream``NEWLINE_TOKENsources. Those all have their heads up their ***es and they all are terribly biased at the onset.NEWLINE_TOKENThey predetermine their outcomes. Have to, to keep their jobs!  Same goes for most tv docs. NEWLINE_TOKENThey are instructed by their network, ``This is how your show will look.`` One semi-decent one,NEWLINE_TOKENjust semi, was Sasquatch: Legend Meets Science  by White Wolf Productions, now on dvd.NEWLINE_TOKENNEWLINE_TOKENJeff`\n",
      "\n",
      "\n",
      "35234435\n",
      "False\n",
      "`NEWLINE_TOKENNEWLINE_TOKEN: i think the issue with this ``average human being`` vs. ``you`` thing is one of writing a techinical or descriptive article (as opposed to a short story or a ``how too`` article or something similar) is the use of the ``second person``.  it is often frowned on by the profs i had in college to put in personal pronouns into a techinical or descriptive article.  it's a matter of style, i agree, but i also think that the use of personal pronouns can almost always be avoided.  `\n",
      "\n",
      "\n",
      "42448507\n",
      "True\n",
      "`( ) you are SUCH a fucking twat flapNEWLINE_TOKENNEWLINE_TOKENPosition // Artist, Band, or Group // Song Title // Weeks Spent At #1 // YearNEWLINE_TOKENNEWLINE_TOKEN1. Mariah Carey & Boyz II Men- ``One Sweet Day``- [16 weeks] (1995)NEWLINE_TOKEN2. Boyz II Men- ``End of the Road``- [14 weeks] (1992)NEWLINE_TOKEN3. Whitney Houston- ``I Will Always Love You``- [14 weeks] (1992)NEWLINE_TOKEN4. Los Del Rio- ``Macarena (Bayside Boys Mix)``- [14 weeks] (1996) NEWLINE_TOKEN5. Elton John- ``Candle In The Wind``- [14 weeks] (1997)NEWLINE_TOKEN6. Mariah Carey- ``We Belong Together``- [14 weeks] (2005)NEWLINE_TOKEN7. Boyz II Men- ``I'll Make Love To You``- [13 weeks] (1994)NEWLINE_TOKEN8. Monica & Brandy- ``The Boy Is Mine``- [13 weeks] (1998)NEWLINE_TOKEN9. Santana featuring Rob Thomas- ``Smooth``- [12 weeks] (2000)NEWLINE_TOKEN10. Eminem- ``Lose Yourself``- [12 weeks] (2002)NEWLINE_TOKEN11. Usher featuring Lil Jon & Ludacris- ``Yeah!``- [12 weeks] (2004)NEWLINE_TOKEN12. All-4-One- ``I Swear``- [11 weeks] (1994)NEWLINE_TOKEN13. Toni Braxton- Un-break My Heart``- [11 weeks] (1996)NEWLINE_TOKEN14. Puff Daddy & Faith Evans featuring 112- ``I'll Be Missing You``- [11 weeks] (1997)NEWLINE_TOKEN15. Destiny's Child- ``Independent Woman Part I``- [11 weeks] (2000)NEWLINE_TOKEN16. Olivia Newton John- ``Physical``- [10 weeks] (1981)NEWLINE_TOKEN17. Santana featuring the Product G&B-; ``Maria Maria``- [10 weeks] (2000)NEWLINE_TOKEN18. Ashanti- ``Foolish``- [10 weeks] (2002)NEWLINE_TOKEN19. Nelly & Kelly Rowland- ``Dilemna``- [10 weeks] (2002)NEWLINE_TOKEN20. Kanye West featuring Jamie Fox- ``Gold Digger``- [10 weeks] (2005)NEWLINE_TOKEN21. Kim Carnes- ``Betty Davis Eyes``- [9 weeks] (1981)NEWLINE_TOKEN22. Diana Ross & Lionel Richie- ``Endless Love``- [9 weeks] (1981)NEWLINE_TOKEN23. 50 Cent- ``In Da Club``- [9 weeks] (2003)NEWLINE_TOKEN24. Beyonc� Featuring Sean Paul- ``Baby Boy``- [9 weeks] (2003)NEWLINE_TOKEN25. Outkast- ``Hey Ya!``- [9 weeks] (2003)NEWLINE_TOKEN26. Mario- ``Let Me Love You``- [9 weeks] (2005)NEWLINE_TOKEN27. The Police- ``Every Breath You Take``- [8 weeks] (1983)NEWLINE_TOKEN28. Kris Kross- ``Jump``- [8 weeks] (1992) NEWLINE_TOKEN29. Janet Jackson- ``That's the Way Love Goes``- [8 weeks] (1993)NEWLINE_TOKEN30. Mariah Carey- ``Dreamlover``- [8 weeks] (1993)NEWLINE_TOKEN31. Mariah Carey- ``Fantasy``- [8 weeks] (1995)NEWLINE_TOKEN32. Bone Thugz-N-Harmony- ``That Crossroads``- [8 weeks] (1996)NEWLINE_TOKEN33. Beyonce featuring Jay-Z- ``Crazy In Love``- [8 weeks] (2003)NEWLINE_TOKEN34. Usher- ``Burn``- [8 weeks] (2004)NEWLINE_TOKEN35. 50 Cent featuring Olivia- ``Candy Shop``- [8 weeks] (2005)NEWLINE_TOKEN36. Joan Jett & The Blackhearts- ``I Love Rock N Roll``- [7 weeks] (1982)NEWLINE_TOKEN37. Paul McCartney & Stevie Wonder- ``Ebony and Ivory``- [7 weeks] (1982)NEWLINE_TOKEN38. Michael Jackson- ``Billie Jean``- [7 weeks] (1983)NEWLINE_TOKEN39. Bryan Adams- ``(Everything I Do) I Do It For You``- [7 weeks] (1991)NEWLINE_TOKEN40. Michael Jackson- ``Black or White``- [7 weeks] (1991)NEWLINE_TOKEN41. Snow- ``Informer``- [7 weeks] (1993)NEWLINE_TOKEN42. UB40- ``Can't Help Falling In Love``- [7 weeks] (1993)NEWLINE_TOKEN43. Madonna- ``Take A Bow``- [7 weeks] (1995)NEWLINE_TOKEN44. Montell Joran- ``This Is How We Do It``- [7 weeks] (1995)NEWLINE_TOKEN45. TLC- ``Waterfalls``- [7 weeks] (1995)NEWLINE_TOKEN46. Janet Jackson- ``All For You``- [7 weeks] (2001)NEWLINE_TOKEN47. Nelly- ``Hot In Herre``- [7 weeks] (2002)NEWLINE_TOKEN48. Ciara featuring Petey Pablo- ``Goodies``- [7 weeks] (2004)NEWLINE_TOKEN49. Blondie- ``Call Me``- [6 weeks] (1980)NEWLINE_TOKEN50. Kenny Rogers- ``Lady``- [6 weeks] (1980)NEWLINE_TOKEN51. The J. Geils Band- ``Centerfold``- [6 weeks] (1982)NEWLINE_TOKEN52. Survivor- ``Eye of the Tiger``- [6 weeks] (1982)NEWLINE_TOKEN53. Irene Cara- ``Flashdance... What A Feeling``- [6 weeks] (1983)NEWLINE_TOKEN54. Michael Jackson & Paul McCartney- ``Say Say Say``- [6 weeks] (1983)NEWLINE_TOKEN55. Madonna- ``Like A Virgin``- [6 weeks] (1984)NEWLINE_TOKEN56. Boyz II Men- ``On Bended Knee``- [6 weeks] (1994)NEWLINE_TOKEN57. Ace of Base- ``The Sign``- [6 weeks] (1994)NEWLINE_TOKEN58. Celine Dion- ``Because You Loved Me``- [6 weeks] (1996)NEWLINE_TOKEN59. Puff Daddy featuring Mase- ``Can't Nobody Hold Me Down``- [6 weeks] (1997)NEWLINE_TOKEN60. R.Kelly & Celine Dion- ``I'm Your Angel``- [6 weeks] (1998)NEWLINE_TOKEN61. Alicia Keys- ``Fallin``- [6 weeks] (2001)NEWLINE_TOKEN62. Mary J. Blige- ``Family Affair``- [6 weeks] (2001)NEWLINE_TOKEN63. Usher- ``U Got It Bad``- [6 weeks] (2001)NEWLINE_TOKEN64. Jennifer Lopez featuring Ja Rule- ``Aint It Funny (Murder Remix)- [6 weeks] (2002)NEWLINE_TOKEN65. Usher & Alicia Keys- ``My Boo``- [6 weeks] (2004)NEWLINE_TOKEN66. John Lennon- ``(Just Like) Starting Over``- [5 weeks] (1980)NEWLINE_TOKEN67. Van Halen- ``Jump`` - [5 weeks] (1984)NEWLINE_TOKEN68. Prince- ``When Doves Cry``- [5 weeks] (1984)NEWLINE_TOKEN69. Paula Abdul- ``Rush, Rush``- [5 weeks] (1991)NEWLINE_TOKEN70. Vanessa Williams- ``Save The Best For Last``- [5 weeks] (1992)NEWLINE_TOKEN71. Sir Mix-A-Lot- ``Baby Got Back``- [5 weeks] (1992)NEWLINE_TOKEN72. Meat Loaf- ``I'd Do Anything For Love (But I Won't Do That)``- [5 weeks] (1993)NEWLINE_TOKEN73. Bryan Adams- ``Have You Ever Really Loved A Woman?- [5 weeks] (1995)NEWLINE_TOKEN74. Ricky Martin- ``Livin La Vida Loca``- [5 weeks] (1999)NEWLINE_TOKEN75. Jennifer Lopez- ``If You Had My Love``- [5 weeks] (1999)NEWLINE_TOKEN76. Christina Aguilera- ``Genie In A Bottle``- [5 weeks] (1999)NEWLINE_TOKEN77. Christina Aguilera, Lil' Kim, Mya & Pink- ``Lady Marmalade``- [5 weeks] (2001)NEWLINE_TOKEN78. Destiny's Child- ``Bootylicious``- [5 weeks] (2001)NEWLINE_TOKEN79. Jennifer Lopez featuring Ja Rule- ``I'm Real (Murder Remix)``- [5 weeks] (2001)NEWLINE_TOKEN80. Chris Brown- ``Run It!``- [5 weeks] (2005)NEWLINE_TOKEN81. Beyonce featuring Slim Thug- ``Check On It``- [5 weeks] (2006)NEWLINE_TOKEN82. Michael Jackson- ``Rock With You``- [4 weeks] (1980)NEWLINE_TOKEN83. Queen- ``Crazy Little Thing Called Love``- [4 weeks] (1980)NEWLINE_TOKEN84. Pink Floyd- ``Another Brick In The Way Part II``- [4 weeks] (1980)NEWLINE_TOKEN85. Lipps, Inc- ``Funkytown``- [4 weeks] (1980)NEWLINE_TOKEN86. Olivia Newton-John- ``Magic``- [4 weeks] (1980)NEWLINE_TOKEN87. Diana Ross- ``Upside Down``- [4 weeks] (1980)NEWLINE_TOKEN88. John Mellencamp- ``Jack & Diane``- [4 weeks] (1982)NEWLINE_TOKEN89. Daryl Hall & John Oates- ``Maneater``- [4 weeks] (1982)NEWLINE_TOKEN90. Men At Work- ``Down Under``- [4 weeks] (1983)NEWLINE_TOKEN91. Bonnie Tyler- ``Total Eclipse of the Heart``- [4 weeks] (1983)NEWLINE_TOKEN92. Lionel Richie- ``All Night Long (All Night)``- [4 weeks] (1983)NEWLINE_TOKEN93. Lionel Richie- ``Say You, Say Me``- [4 weeks] (1985)NEWLINE_TOKEN94. Dionne & Friends- ``That's What Frinds Are For``- [4 weeks] (1986)NEWLINE_TOKEN95. Bangels- ``Walk Like An Egyptian``- [4 weeks] (1986)NEWLINE_TOKEN96. Bon Jovi- ``Livin on a Prayer``- [4 weeks] (1987)NEWLINE_TOKEN97. George Michael- ``Faith``- [4 weeks] (1987)NEWLINE_TOKEN98. Steve Winwood- ``Roll With It``- [4 weeks] (1988)NEWLINE_TOKEN99. Janet Jackson- ``Miss You Much``- [4 weeks] (1989)NEWLINE_TOKEN100. Phil Collins- ``Another Day In Paradise``- [4 weeks] (1989)NEWLINE_TOKEN101. Sinead O'Conner- ``Nothing Compares 2 U``- [4 weeks] (1990)NEWLINE_TOKEN102. Mariah Carey- ``Vision of Love``- [4 weeks] (1990)NEWLINE_TOKEN103. Stevie B.- ``Because I Love You (The Postman Song)``- [4 weeks] (1990)NEWLINE_TOKEN104. Mariah Carey- ``Hero``- [4 weeks] (1993)NEWLINE_TOKEN105. Celine Dion- ``The Power of Love``- [4 weeks] (1994)NEWLINE_TOKEN106. R.Kelly- ``Bump N' Grind``- [4 weeks] (1994)NEWLINE_TOKEN107. TLC- ``Creep``- [4 weeks] (1995)NEWLINE_TOKEN108. Spice Girls- ``Wannabe``- [4 weeks] (1997)NEWLINE_TOKEN109. Next- ``Too Close``- [4 weeks] (1998)NEWLINE_TOKEN110. Aerosmith- ``I Don't Wanna Miss A Thing``- [4 weeks] (1998)NEWLINE_TOKEN111. Monica- ``The First Night``- [4 weeks] (1998)NEWLINE_TOKEN112. Monica- ``Angel of Mine``- [4 weeks] (1999)NEWLINE_TOKEN113. Cher- ``Believe``- [4 weeks] (1999)NEWLINE_TOKEN114. TLC- ``No Scrubs``- [4 weeks] (1999)NEWLINE_TOKEN115. Savage Garden- ``I Knew I Loved You``- [4 weeks] (2000)NEWLINE_TOKEN116. Madonna- ``Music``- [4 weeks] (2000)NEWLINE_TOKEN117. Christina Aguilera- ``Come On Over Baby (All I Want Is You)``- [4 weeks] (2000)NEWLINE_TOKEN118. Joe featuring Mystikal- ``Shutter``- [4 weeks] (2001)NEWLINE_TOKEN119. Usher- ``U Remind Me``- [4 weeks] (2001)NEWLINE_TOKEN120. Nickleback- ``How You Remind Me``- [4 weeks] (2001)NEWLINE_TOKEN121. Jennifer Lopez featuring LL Cool J- ``All I Have``- [4 weeks] (2003)NEWLINE_TOKEN122. 50 Cent featuring Nate Dogg- ``21 Questions``- [4 weeks] (2003)NEWLINE_TOKEN123. Nelly, P.Diddy, & Murphy Lee- ``Shake Ya Tailfeather``- [4 weeks] (2003)NEWLINE_TOKEN124. Gwen Stefani- ``Hollaback Girl``- [4 weeks] (2005)Position // Artist, Band, or Group // Song Title // Weeks Spent At #1 // YearNEWLINE_TOKENNEWLINE_TOKEN1. Mariah Carey & Boyz II Men- ``One Sweet Day``- [16 weeks] (1995)NEWLINE_TOKEN2. Boyz II Men- ``End of the Road``- [14 weeks] (1992)NEWLINE_TOKEN3. Whitney Houston- ``I Will Always Love You``- [14 weeks] (1992)NEWLINE_TOKEN4. Los Del Rio- ``Macarena (Bayside Boys Mix)``- [14 weeks] (1996) NEWLINE_TOKEN5. Elton John- ``Candle In The Wind``- [14 weeks] (1997)NEWLINE_TOKEN6. Mariah Carey- ``We Belong Together``- [14 weeks] (2005)NEWLINE_TOKEN7. Boyz II Men- ``I'll Make Love To You``- [13 weeks] (1994)NEWLINE_TOKEN8. Monica & Brandy- ``The Boy Is Mine``- [13 weeks] (1998)NEWLINE_TOKEN9. Santana featuring Rob Thomas- ``Smooth``- [12 weeks] (2000)NEWLINE_TOKEN10. Eminem- ``Lose Yourself``- [12 weeks] (2002)NEWLINE_TOKEN11. Usher featuring Lil Jon & Ludacris- ``Yeah!``- [12 weeks] (2004)NEWLINE_TOKEN12. All-4-One- ``I Swear``- [11 weeks] (1994)NEWLINE_TOKEN13. Toni Braxton- Un-break My Heart``- [11 weeks] (1996)NEWLINE_TOKEN14. Puff Daddy & Faith Evans featuring 112- ``I'll Be Missing You``- [11 weeks] (1997)NEWLINE_TOKEN15. Destiny's Child- ``Independent Woman Part I``- [11 weeks] (2000)NEWLINE_TOKEN16. Olivia Newton John- ``Physical``- [10 weeks] (1981)NEWLINE_TOKEN17. Santana featuring the Product G&B-; ``Maria Maria``- [10 weeks] (2000)NEWLINE_TOKEN18. Ashanti- ``Foolish``- [10 weeks] (2002)NEWLINE_TOKEN19. Nelly & Kelly Rowland- ``Dilemna``- [10 weeks] (2002)NEWLINE_TOKEN20. Kanye West featuring Jamie Fox- ``Gold Digger``- [10 weeks] (2005)NEWLINE_TOKEN21. Kim Carnes- ``Betty Davis Eyes``- [9 weeks] (1981)NEWLINE_TOKEN22. Diana Ross & Lionel Richie- ``Endless Love``- [9 weeks] (1981)NEWLINE_TOKEN23. 50 Cent- ``In Da Club``- [9 weeks] (2003)NEWLINE_TOKEN24. Beyonc� Featuring Sean Paul- ``Baby Boy``- [9 weeks] (2003)NEWLINE_TOKEN25. Outkast- ``Hey Ya!``- [9 weeks] (2003)NEWLINE_TOKEN26. Mario- ``Let Me Love You``- [9 weeks] (2005)NEWLI\n",
      "\n",
      "\n",
      "44851839\n",
      "False\n",
      "Checkuser is not absolutely exactly about this point!\n",
      "\n",
      "\n",
      "44991110\n",
      "False\n",
      "RedirectNEWLINE_TOKEN:I think social housing is better explained under subsidized housing, which incorporates several different versions/methods including Public Housing.  Please respond at the talk page.\n",
      "\n",
      "\n",
      "45600508\n",
      "False\n",
      "`NEWLINE_TOKENNEWLINE_TOKEN==  ==NEWLINE_TOKENNEWLINE_TOKENHi, please turn the fair use images on this page (I understand you used to use that username) into a list of links or something like that as soon as possible. Wikipedia policy doesn't allow fair use images to be displayed in userspace (see Wikipedia:Fair use#Policy), and acording to  you have 56 of them on that page (if you have fair use images on other userspace pages please fix those too). Thanks in advance.   `\n",
      "\n",
      "\n",
      "49729677\n",
      "True\n",
      "NEWLINE_TOKENNEWLINE_TOKEN== Here is a giant vagina photograph ==NEWLINE_TOKENNEWLINE_TOKEN\n",
      "\n",
      "\n",
      "54089909\n",
      "False\n",
      "` 2006 (UTC)NEWLINE_TOKENNEWLINE_TOKENI have deleted the blurb that ``(he [Trey Parker] speaks the language fluently; this is attributed to him living in Japan for a period)`` until it can be substantiated. The pronunciation issue (``kintama no kame``, ``kinka`` for ``kenka``) as well as grammatically issues (``kami`` instead of ``ke`` for pubic hair) et cetera call his Japanese language proficiency into question. I am sure he knows some Japanese, but I don't buy fluency for a second.  20:56, 19 May`\n",
      "\n",
      "\n",
      "58088361\n",
      "False\n",
      "`NEWLINE_TOKEN{| style=``border-spacing:8px;margin:0px -8px`` width=``100%``NEWLINE_TOKEN|class=``MainPageBG`` style=``width: 55%; border:1px solid #084080; background-color:#F5FFFA; vertical-align:top;color:#000000;font-size: 85%``|NEWLINE_TOKEN{| width=``100%`` cellpadding=``2`` cellspacing=``5`` style=``vertical-align:top; background-color:#F5FFFA``NEWLINE_TOKEN!  Hello Remis, and welcome to Wikipedia! Here are some recommended guidelines to help you get involved. Please feel free to contact me if you need help with anything. Best of luck and happy editing!  NEWLINE_TOKEN|}NEWLINE_TOKEN{| style=``border-spacing:8px;margin:0px -8px`` width=``100%``NEWLINE_TOKEN|class=``MainPageBG`` style=``width: 55%; border:1px solid #FFFFFF; background-color:#F5FFFA; vertical-align:top``|NEWLINE_TOKEN{| width=``100%`` cellpadding=``2`` cellspacing=``5`` style=``vertical-align:top; background-color:#F5FFFA``NEWLINE_TOKEN! Getting startedNEWLINE_TOKEN|-NEWLINE_TOKEN|style=``color:#000``|NEWLINE_TOKEN* Wikipedia TutorialNEWLINE_TOKEN* How to edit a pageNEWLINE_TOKEN* The five pillars of WikipediaNEWLINE_TOKEN* Manual of StyleNEWLINE_TOKEN* Be bold in editingNEWLINE_TOKEN* How to write a great articleNEWLINE_TOKEN* WikiProjectsNEWLINE_TOKEN|-NEWLINE_TOKEN! Getting your info out thereNEWLINE_TOKEN|-NEWLINE_TOKEN| style=``color:#000``|NEWLINE_TOKEN* Cite your sourcesNEWLINE_TOKEN* Neutral Point of ViewNEWLINE_TOKEN* Point of ViewNEWLINE_TOKEN* VerifiabilityNEWLINE_TOKEN* Uploading imagesNEWLINE_TOKEN* Image use policyNEWLINE_TOKEN|-NEWLINE_TOKEN! Getting more Wikipedia rulesNEWLINE_TOKEN|-NEWLINE_TOKEN| style=``color:#000``|NEWLINE_TOKEN* Policy LibraryNEWLINE_TOKEN|-NEWLINE_TOKEN|}NEWLINE_TOKEN|class=``MainPageBG`` style=``width: 55%; border:1px solid #FFFFFF; background-color:#F5FFFA; vertical-align:top``|NEWLINE_TOKEN{| width=``100%`` cellpadding=``2`` cellspacing=``5`` style=``vertical-align:top; background-color:#F5FFFA``NEWLINE_TOKEN! Getting helpNEWLINE_TOKEN|-NEWLINE_TOKEN|style=``color:#000``|NEWLINE_TOKEN* New contributors' help pageNEWLINE_TOKEN* Where to ask a questionNEWLINE_TOKEN* Help DeskNEWLINE_TOKEN* Frequently Asked QuestionsNEWLINE_TOKEN|-NEWLINE_TOKEN! Getting alongNEWLINE_TOKEN|-NEWLINE_TOKEN|style=``color:#000``|NEWLINE_TOKEN* WikipediansNEWLINE_TOKEN* WikiquetteNEWLINE_TOKEN* CivilityNEWLINE_TOKEN* Sign your postsNEWLINE_TOKEN* Conflict resolutionNEWLINE_TOKEN|-NEWLINE_TOKEN! Getting technicalNEWLINE_TOKEN|-NEWLINE_TOKEN|style=``color:#000``|NEWLINE_TOKENNEWLINE_TOKEN* Pages needing attentionNEWLINE_TOKEN* Peer reviewNEWLINE_TOKEN* UtilitiesNEWLINE_TOKEN* Village pumpNEWLINE_TOKEN|-NEWLINE_TOKEN|}NEWLINE_TOKEN|}NEWLINE_TOKEN|}`\n",
      "\n",
      "\n",
      "64101618\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKEN== Bandai and Nintendo ==NEWLINE_TOKENNEWLINE_TOKENOn the packaging of a number of Nintendo consoles, the Bandai logo was printed. This was the case for at least the European version of the NES, Gameboy and SNES. Does anyone know why the logo is on the packaging of these consoles? The only reason I can think of, is that maybe Bandai could have distributed the consoles in Europe...\n",
      "\n",
      "\n",
      "65073830\n",
      "False\n",
      "`::Aiden, I think you might want to change your password to Wikipedia. Someone using your ID posted the following, above, ``I wouldn't have a problem with the Jesus template being on top, but the Christianity template should not be confined to the one small Christian views section. How about this: We place the Christianity template in the Life and teachings based on the Gospels section? �, 18 July 2006 (UTC).`` Based on the current post, I can only assume that the other post was a forgery.  NEWLINE_TOKENNEWLINE_TOKEN`\n",
      "\n",
      "\n",
      "71212682\n",
      "True\n",
      ". Crzrussian, slit your wrists\n",
      "\n",
      "\n",
      "81964518\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKEN:Try using the dlw template, or re-sourcing. Failing that, simply remove the URL, but keep a plain text reference to the original source.\n",
      "\n",
      "\n",
      "91982571\n",
      "False\n",
      "`*That was a ridiculous comment. The source is by no means ``dubious`` or ``amateur`` and by claiming such you obviously didn't read the article whatsoever. I find it hysterical you claim if it was of any significance, it would be mentioned in the ``news`` or ``newspapers``. First of all, the article itself is from National Geographic, so it obviously was in the news, secondly, newspapers are nowhere considered as a reliable source when compared to an academic journal. The study I cited does prove quite a bit and is carried out by a respected geneticist. I have provided a reliable source and links to Maltese hIstory to support what most people obviously recognize, while you only provided some garbage POV link to a newspaper article with no references and that has nothingto do with Maltese people. Also, by being related to Arabs does not mean Maltese are necessarily Arabs and there are many Lebanese who seak Arabic, but also don't even consider themselves Arabs because of their distinct non-Arab ancestry, especially amongst Lebanese christians. Tunisians and other North Africans were largely Arabized in language and culture but are of non-Arab origins, and are of predominantly Berber origins and retain Berber culture, even among Arabized Berbers. Maltese speak a Semitic language and are of very significant Phoenician descent which clearly links them to Lebanese and also to Tunisians. Considering the Maltese language is a Semitic language very similar to Tunisian Arabic, obviously there would also be Arab cultural influences as well. They are related to all Arabs in terms of language, but are specifically very closely related to Lebanese and Tunisians due to common Pheoenician ancestry and also share many cultural aspects with Tunisians.  NEWLINE_TOKENNEWLINE_TOKEN`\n",
      "\n",
      "\n",
      "93053828\n",
      "False\n",
      "NEWLINE_TOKEN:Why, thanks! ^___^ -\n",
      "\n",
      "\n",
      "97931190\n",
      "False\n",
      "`NEWLINE_TOKENNEWLINE_TOKEN:Yagli gures is the traditional Turkish sport from the Ottoman times, and probably from the times of the Turkic migration. However, nowadays football has become the ``national`` sport in the sense that it is the most popular, both in numbers of players and viewers. I will try to word it better.  `\n",
      "\n",
      "\n",
      "104828546\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKEN== ledgend status ==NEWLINE_TOKENNEWLINE_TOKENalthough this is not something that can be technically claimed, i think it has to be mentioned the status that he has gained as ledgend online and on T.V\n",
      "\n",
      "\n",
      "105144678\n",
      "False\n",
      "NEWLINE_TOKEN:You reverted in error. I didn't remove any material. I a) changed comic punctuation marks as per MOS and added pertinent info about Hoffman; b) added info about levitation claim on packaging.\n",
      "\n",
      "\n",
      "109354804\n",
      "False\n",
      "NEWLINE_TOKEN:: No thanks, O'Brien - though you also play your part well.\n",
      "\n",
      "\n",
      "109972229\n",
      "False\n",
      "```PETA is not a self-published source.`` Please explain how the PETA website is not ``self-published``.  NEWLINE_TOKENNEWLINE_TOKEN`\n",
      "\n",
      "\n",
      "110360899\n",
      "False\n",
      "`His tours ended ten years ago. Both Elvis and MJ have made music that will be listened to 100 years from now and even longer - yeah sure, people thought that about Bing Crosby and many others. Some MJ songs, like ``Billie Jean,`` could have been released today and they would be thought of as ``modern.`` - Hahahahahahahaha, thank I needed a good laugh! Thriller sounds almost as dated as Off the Wall. Is this figure for ``record``/albums, or does it include singles sales and just about everything else? - Most of Bing's sales are singles. A delusional site claimed 900 million (and 1.1 billion for Elvis) - Far less delusional than WJ's mentally ill fans claiming 750 million sales, when the actual number is 300 million. I'd be willing to buy something in between 200 to 400 million for Crosby (likely towards the lower end), but the problem is that not many sources mention this. I don't know if it's because Bing Crosby has been largely forgotten now - Yeah dream on, Crosby's sales were well over 400 million by 1980, 27 years ago, and it's funny that this ``largely forgotten`` entertainer has the biggest selling jazz album at amazon. Bing is more important than Jackson in every way, influence and sales, and he didn't need any promoters or producers to help him. ( )NEWLINE_TOKENNEWLINE_TOKEN`\n",
      "\n",
      "\n",
      "111711361\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKEN== RE:wow ==NEWLINE_TOKENNEWLINE_TOKENI see exactly what you mean, its a strange approach but I suppose they are humans, with their lives and beliefs that contribute to this, its just up to a majority to temper their passion.\n",
      "\n",
      "\n",
      "114421458\n",
      "False\n",
      "`NEWLINE_TOKENNEWLINE_TOKEN== You're famous! ==NEWLINE_TOKENNEWLINE_TOKENIt looks like you've finally gotten the recognition you deserve: , you inbred little kite. `\n",
      "\n",
      "\n",
      "114780795\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKEN== T. Hawk ==NEWLINE_TOKENHi, I'm just wondering why you think the height info is too difficult to verify on T. Hawk's page. Surely there is no one even close to 7'7. I saw that Hugo was listed as 7'2 and he is the only other character I thought could have been as tall.\n",
      "\n",
      "\n",
      "119853676\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKEN: Thanks for the award! -\n",
      "\n",
      "\n",
      "126503777\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKEN== Re: Center for Neighborhood Technology ==NEWLINE_TOKENNEWLINE_TOKENIf you feel that this article is too short please edit it to add more content. However, links to articles on external websites are not generally considered very useful in Wikipedia articles. For more information on external links please look at our external links policy. �\n",
      "\n",
      "\n",
      "133200847\n",
      "True\n",
      "`NEWLINE_TOKENNEWLINE_TOKEN: Of course... you called me a ``sock puppet`` rigth after your first editwar, liar.  `\n",
      "\n",
      "\n",
      "135366244\n",
      "False\n",
      "Why did ya banned my cuzin???I think ya pushing this to far!!memeco came here to do work but probably had an arguement with somebody!that doesnt mean he needs to be blocked!He is trying to establish himself in wikipedia, and ya are not giving him time for him to learn the way things work around here!Ya should take easy instead of blocking people because they still could come back so it will be useless to block them!i think ya should be more calm!Memeco stoped arguing after his first day and ya didnt even give any chance to apologize or anything!wtf is wrong over here?are ya monopolizing wikipedia?!This is becoming so sad now!i feel bad for the Future of wikipedia NEWLINE_TOKENNEWLINE_TOKEN\n",
      "\n",
      "\n",
      "136331902\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKENCompletely rewritten to be more adherent to standards\n",
      "\n",
      "\n",
      "138391118\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKEN* Merge - While I disagree that Underutilized crops reads like a wiktionary entry, the neglected crops article is clearly a stub, and I see no reason not to merge it into this article.\n",
      "\n",
      "\n",
      "138799406\n",
      "True\n",
      "NEWLINE_TOKENChristian Regenhard now jhas an article. Shame on you Jerskine and Citizen Dick for being cold emotionless MONSTERS! You should do research and see that the Christian made the ultimate sacrifice along with 343 other firefighters in trying to save lives. His death launched a national organization and movement and made his mother Sally the accidential activist. Her work will prevent other mothers from suffering the pain that she will have to live with for the rest of her life. I should send a copy of this to the local Co-op City Times and the Fifrefighters Society to show how ignorant and soul-less both of you morons are.\n",
      "\n",
      "\n",
      "138833643\n",
      "False\n",
      "`NEWLINE_TOKEN::::This was an accurate redirect, I hope that ``church`` catches on fire one day, and is RAZED into the ground with the twisted deamons that are a part of that cult. The sickos use friggin children to promote their messages from hell.  NEWLINE_TOKENNEWLINE_TOKEN`\n",
      "\n",
      "\n",
      "139079604\n",
      "False\n",
      "to themselves and the former enemy\n",
      "\n",
      "\n",
      "141593838\n",
      "True\n",
      "NEWLINE_TOKENGood Ridance! Please take your silly friend BigD with you\n",
      "\n",
      "\n",
      "143886432\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKEN==List of VFL/AFL records==NEWLINE_TOKENI just wanted to say great work on the page; i added a list and i will be updating it at the end of each round. If you have any ideas of what else could be added to the page i would be glad to help.\n",
      "\n",
      "\n",
      "150753018\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKEN== Shanty towns ==NEWLINE_TOKENNEWLINE_TOKENAre there any pictures available of the shanty towns?\n",
      "\n",
      "\n",
      "152780853\n",
      "False\n",
      "`NEWLINE_TOKENNEWLINE_TOKEN== Derivation of relation between gravitational constant and electron wavelength ==NEWLINE_TOKENNEWLINE_TOKENHi Don, on  you wrote: NEWLINE_TOKENNEWLINE_TOKEN``As noted under Matter-wave quantum, the Planck constant can be derived from the electron mass, light velocity and the gravitational constant.NEWLINE_TOKENh = 2mc(3Gm)exp 1/3, times(2pi)exp 5/3``NEWLINE_TOKENNEWLINE_TOKENCould you show me shortly how it can be derived so I could save time otherwise wasted onr looking for the derivation. Of course I understand that  but I miss relation between  and .  `\n",
      "\n",
      "\n",
      "154107027\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKEN== Protected Article? ==NEWLINE_TOKENNEWLINE_TOKENWhy is this article protected?  Which administrators would I talk to about entering new information, more specifically into the trivia section.  There is some information on this book that I would like to add to this particular article.NEWLINE_TOKENNEWLINE_TOKEN\n",
      "\n",
      "\n",
      "170264727\n",
      "True\n",
      "NEWLINE_TOKENNEWLINE_TOKEN==  IS STANDAHL A RACIST AND ETHIC DIVIDER LIKE HIS FRIEND CARLOS? ==NEWLINE_TOKENNEWLINE_TOKENHIS ACTIONS ARE SUSPECT AND APPARENTLY UNEVENLY AND UNFAIRLY DISTRIBUTED.\n",
      "\n",
      "\n",
      "171370469\n",
      "True\n",
      "NEWLINE_TOKENNEWLINE_TOKENCan't you at least have the common courtesy to answer my question, or do you just want to be a jerk?\n",
      "\n",
      "\n",
      "177130614\n",
      "False\n",
      "bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla  bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla b\n",
      "\n",
      "\n",
      "187222780\n",
      "False\n",
      "... not to mention it seems well sourced. (  )\n",
      "\n",
      "\n",
      "188846702\n",
      "False\n",
      "`==Copyright problems==NEWLINE_TOKENHello, . Concerning your contribution, Tom Kovac, we cannot accept copyrighted text or images borrowed from either web sites or printed material without the permission of the author.  As a copyright violation, Tom Kovac appears to qualify for deletion under the speedy deletion criteria. Tom Kovac has been tagged for deletion, and may have been deleted by the time you see this message. For text material, please consider rewriting the content and citing the source, provided that it is credible.NEWLINE_TOKENNEWLINE_TOKENIf you believe that the article or image is not a copyright violation, or if you have permission from the copyright holder to release the content freely under the GNU Free Documentation License (GFDL) then you should do one of the following:NEWLINE_TOKENNEWLINE_TOKEN:*If you have permission from the author, leave a message explaining the details at Talk:Tom Kovac and send an email with the message to ``permissions-en (at) wikimedia (dot) org``. See Wikipedia:Requesting copyright permission for instructions.NEWLINE_TOKEN:*If a note on the original website states that re-use is permitted under the GFDL or released into the public domain leave a note at Talk:Tom Kovac with a link to where we can find that note. NEWLINE_TOKEN:*If you own the copyright to the material: send an e-mail from an address associated with the original publication to permissions-en(at)wikimedia(dot)org or a postal message to the Wikimedia Foundation permitting re-use under the GFDL, and note that you have done so on Talk:Tom Kovac. NEWLINE_TOKENNEWLINE_TOKENHowever, for text content, you may want to consider rewriting the content in your own words. Thank you, and please feel free to continue contributing to Wikipedia.   (|) `\n",
      "\n",
      "\n",
      "190464291\n",
      "False\n",
      "```Hanging on the telephone`` - Blondie. I Heart Blondie -)NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKEN`\n",
      "\n",
      "\n",
      "193041148\n",
      "False\n",
      "NEWLINE_TOKENIts a Neutral Position its not a NO and its not a straight away YES.\n",
      "\n",
      "\n",
      "203431340\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKEN====Suspected Sockpuppeteer Turns Out to Be a Human====NEWLINE_TOKENShocking news break.  It turns out that the person who originally supplied the information in ISM is me!  A real NEWLINE_TOKENNEWLINE_TOKENperson.... not a 'sock puppeteer.'  There are no socks and no puppets.  Just a real person who thought that a NEWLINE_TOKENNEWLINE_TOKENbusiness was significant enough to warrant a pace on Wikipedia.  Someone who actually understands the business he is NEWLINE_TOKENNEWLINE_TOKENin, unlike the editors, who have no experience in the field whatsoever.NEWLINE_TOKENNEWLINE_TOKENIt turns out- or so we can surmise, that there are lots of people who want to learn about this company.  Oh no!  NEWLINE_TOKENNEWLINE_TOKENThis can't be!  It's a business... not an encyclopedic fact!  NEWLINE_TOKENNEWLINE_TOKENBut an encyclopedia like Wikipedia should include everything in the world.  otherwise, why does it exist?  NEWLINE_TOKENNEWLINE_TOKENEncyclopedia Britannica and the Oxford Encyclopedia are perfectly sufficient.NEWLINE_TOKENNEWLINE_TOKENGeekish editors have said that listing this company is 'blatant advertising.'  Yet other advertising companies, like NEWLINE_TOKENNEWLINE_TOKENModernista, BBDO, DDB, Ogilvy, etc. are all here... blatant advertising.  So, how big does a company have to be to NEWLINE_TOKENNEWLINE_TOKENbe listed on Wiki?  The answer- there is no answer.  It's all up to the whims of people who have no knowledge nor NEWLINE_TOKENNEWLINE_TOKENexperience in business, who call themselves Carbuncle, Smeff, Dongfart, and the rest.  This is surely detrimental to NEWLINE_TOKENNEWLINE_TOKENthe Wiki.NEWLINE_TOKENNEWLINE_TOKENWhy do people have such a Pyongyang attitude towards this?  The very idea of limiting what is shown here- censoring NEWLINE_TOKENNEWLINE_TOKENpure facts arbitrarily- is against the very idea of a global Wiki.  The great big idea is that this site is NEWLINE_TOKENNEWLINE_TOKENdeveloped by the people of the world, and includes all the things that the published encyclopedias, which have been NEWLINE_TOKENNEWLINE_TOKENaround for hundreds of years, do not or cannot include.NEWLINE_TOKENNEWLINE_TOKENTo my mind, and all the other sane, normal people of the world, this is all ridiculous.  NEWLINE_TOKENNEWLINE_TOKENPlease cite the arguments of What Wiki is Not and all the rest.  It is a shortcut to thinking.  And clearly there is NEWLINE_TOKENNEWLINE_TOKENvery little thinking here.  NEWLINE_TOKENNEWLINE_TOKENI have had repeated emails from people around the world asking why they cannot find ISM on Wikipedia, and many from NEWLINE_TOKENNEWLINE_TOKENpeople who either wanted to add information on the company or were looking for information for research.  Everyone NEWLINE_TOKENNEWLINE_TOKENwas rebuffed.  What kind of person would do this- what kind of person would sit in their little room, hiding NEWLINE_TOKENNEWLINE_TOKENinformation from others, and trying to keep reality away at any cost?  Sock Puppets?  Suspicious users?  Legal NEWLINE_TOKENNEWLINE_TOKENthreats?  What kind of cowardly fool says these things without simply engaging in a dialogue with the person who NEWLINE_TOKENNEWLINE_TOKENoriginally wrote the article and who always- ALWAYS - asked for editor input and support?NEWLINE_TOKENNEWLINE_TOKENGo on- look at the history.  You will see that editor input was always taken at first, despite the fact that all NEWLINE_TOKENNEWLINE_TOKENeditors here are wholly unqualified to make a decision on this subject.  When asked to explain themselves, no one NEWLINE_TOKENNEWLINE_TOKENhad the nous to do so.  Delicious Carbuncle, BlueBoy, Todd1, Fisher Queen, etc.   All refused to answer for their NEWLINE_TOKENNEWLINE_TOKENactions.  Cowards and buffoons who have no sense, courage, nor intelligence. NEWLINE_TOKENNEWLINE_TOKENAnyone who makes an attack on another person, as these 'editors' have, and runs away without facing the person they NEWLINE_TOKENNEWLINE_TOKENhave attacked, is  not deserving of their powers.  NEWLINE_TOKENNEWLINE_TOKENI am now convinced that Wikipedia, despite it's noble origins, is just a place for fools to feel power in a world NEWLINE_TOKENNEWLINE_TOKENwhere they are unable to have any in reality.  Go ahead and add your ridiculous little code to me and my site.  You NEWLINE_TOKENNEWLINE_TOKENhave no argument and have no intelligence- if you think you do, face me like a real human- talk, discuss, and the NEWLINE_TOKENNEWLINE_TOKENrest.  Or be a true Wiki editor and make a stupid, sarcastic comment and run away... hiding... and never respond to NEWLINE_TOKENNEWLINE_TOKENyour comments.NEWLINE_TOKENNEWLINE_TOKENCheers,NEWLINE_TOKENNEWLINE_TOKENKevin NicholasNEWLINE_TOKENKnown as kmnicholasNEWLINE_TOKENor ismbostonNEWLINE_TOKENand, yes, I live in England- of you bothered to askNEWLINE_TOKENand my mobile phone number is 07791 410 501NEWLINE_TOKENso stop making out that I'm hiding or tricking anyone.  I'm, here. And I'll meet you, face to face, any NEWLINE_TOKENNEWLINE_TOKENtime.\n",
      "\n",
      "\n",
      "204675879\n",
      "True\n",
      "NEWLINE_TOKENNEWLINE_TOKEN==Im going to get blocked for this but I don't care==NEWLINE_TOKENNEWLINE_TOKENYOU ARE THE BIGGEST WANKER I HAVE EVER MET ON HERE AND I CANT BELIEVE YOU ARE AN ADMIN. YOU SUCK THE COCKS OF ALL THE OTHER ADMINS BUT YOU'RE AN ABSOLUTE CUNT IN YOUR DEALINGS WITH NEWBIES AND FIRST TIME VANDALS. I COULD HAVE BEEN REFORMED IF A DIFFERENT ADMIN HAD GIVEN ME MY FIRST WARNING BUT NOW THANKS TO YOU IM GOING TO FUCKING VANDALISE THIS HEAP OF SHIT ENCYCLOPEDIA EVERY DAY FOR THE REST OF MY LIFE (IM 12 YEARS OLD FUCKER!)..... HAHHAHAHAH\n",
      "\n",
      "\n",
      "204830437\n",
      "False\n",
      "for the mistakes I made.\n",
      "\n",
      "\n",
      "212521051\n",
      "False\n",
      "`::Certainly, ``the word god is for me nothing more than the expression and product of human weaknesses`` does not on its own indicate an agnostic view, but I do not think it is inconsistent with one, nor is it definitively an atheist view. From the context of the letter (see this abridged translation), it is clear that Einstein was speaking of Jewish monotheism and its biblical basis. His rejection of these in this letter is nothing that was not already known from his previously available words on the matter. One may reject the Jewish conception of god, and any other conception of god, while still acknowledging the possibility of a god as yet unconceived. Given the context of the letter, and the context of Einstein's other complex and nuanced words about God, I don't think we're justified in interpreting this as a definitive expression of atheism.NEWLINE_TOKENNEWLINE_TOKEN::I am not the only one who does not see this newly available quote as an unambiguous expression of atheism: note the evaluation by John Brooke, ``who said the letter lends weight to the notion that 'Einstein was not a conventional theist' � although he was not an atheist, either``, as reported here. Elsewhere in the article, it is acknowledged that Einstein ``expressed complex and arguably contradictory views on faith, perceiving a universe suffused with spirituality while rejecting organized religion.`` Given the complexity (and possibly self-contradictory) nature of Einstein's views, whom will we trust: evaluations of the primary sources made by Wikipedia editors, or those made by reliable secondary sources? I would put much more stock in the latter.   NEWLINE_TOKENNEWLINE_TOKEN`\n",
      "\n",
      "\n",
      "217306299\n",
      "True\n",
      "`NEWLINE_TOKENNEWLINE_TOKEN:Why on earth have you done this? I had said the conversation is concluded - it is Jack who isn't letting it go by going to admins and other editors.  I have �cooled off� (I was only hot for a moment) � and I MUST express myself on my own Talk page. Is this language-censorship? What is it? Jack Forbes gave as good as he got � and my point about him stands. Are you green-lighting Jack Forbes in a general sense ? (and why get involved?) I do need to know this now, as my time is valuable to me: I am questioning why I am on Wikipedia every day at the moment: it has to make sense to me.  I remember you from the BI nationality dispute (before you were an admin?) - are you too close to this do you think? Please answer these questions.   NEWLINE_TOKENNEWLINE_TOKEN:Actually don't bother: when I look at your opening line ``you've been warned time and again for incivility, personal attacks, edit warring, etc.`` (``etc`` for heaven's sake? Isn't the rest exaggerated enough!) - it simply makes me look like a bad Wikipedian. I'm just not having that. Less than 50% of admins seem to be up to the job, and unfortunately I always feel there should be more. Is worth me staying? Honestly - No. I could appeal yes, but what's the point?: Wikipedia has got to the hysterical point where editing is too-often seen as a crime (and a mark against your name), any old joe can throw around official-looking warnings (do you see me doing it?), too-busy admins simply head-count everything, and incidents are not treated on merit, but on a perceived ``reputation``. Name a developed country that works like that? It is a catch I can't see myself getting out of. I have a lot I still planned to do, but I can't see the merit in staying: Wikipedia has vast power and needs value-driven guideline-obeying people like myself - it is mainly the politicised who seem to understand the power of this place - but life is full of other things, and I can't see myself fitting in here anymore.  NEWLINE_TOKENNEWLINE_TOKEN==RETIRED==NEWLINE_TOKENNEWLINE_TOKENI'm trying to think of who to say goodbye to. One guy's left himself over the farce with football. CarterBar - good luck. RolandR springs to mind. There's a motley bunch at Alzheimer's. I have seen several admins who are in fact very good (shit you guys are up against it!) I'll leave it there.   `\n",
      "\n",
      "\n",
      "223284309\n",
      "False\n",
      "`NEWLINE_TOKEN:::May I suggest you don't take Arcayne's word as Gospel? Arcayne fought tooth and nail a half dozen people over the definition of the word ``Penultimate``. He even claimed that he was an Oxford grad and that the BBC was wrong.  `\n",
      "\n",
      "\n",
      "227579274\n",
      "False\n",
      "`NEWLINE_TOKENNEWLINE_TOKEN:Boy was that difficult. �   `\n",
      "\n",
      "\n",
      "229506661\n",
      "True\n",
      "NEWLINE_TOKENNEWLINE_TOKENCongrats for being a total fucking faggot.NEWLINE_TOKENNEWLINE_TOKEN\n",
      "\n",
      "\n",
      "242620074\n",
      "False\n",
      "NEWLINE_TOKEN:::I see hole punch gives all the synonyms, so I suppose they can be left out of this article.  On the other hand, ticket punch would be more precise, as the purpose of a ticket punch is marking, not preparing paper to go in a ring binder.  An ordinary hole punch won't work on many control cards because the jaw is too short to reach inside the outside rows of cells on a control card.\n",
      "\n",
      "\n",
      "248474826\n",
      "False\n",
      "NEWLINE_TOKEN*The background section already links to that article, as cited in Further reading.  When I added it, I thought it best to just cite it as further reading, rather than include every single detail from it into this article.   It's not what one would call balanced material.\n",
      "\n",
      "\n",
      "252644024\n",
      "True\n",
      "NEWLINE_TOKENNEWLINE_TOKENYou could try that, but it won't work.  You're not smart enough to figure out how to make a block stick.  Moron.\n",
      "\n",
      "\n",
      "255006868\n",
      "False\n",
      "NEWLINE_TOKEN                                                                                                It IS true, so shut up and watch the show, why don't ya?  Bakutrix\n",
      "\n",
      "\n",
      "257998671\n",
      "True\n",
      "NEWLINE_TOKENNEWLINE_TOKEN== if ==NEWLINE_TOKENNEWLINE_TOKENIF YOU HAD ANY GUTS YOU'D BAN ME RIGHT NOWNEWLINE_TOKENNEWLINE_TOKENFAGGOT\n",
      "\n",
      "\n",
      "264745295\n",
      "False\n",
      "`NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENGwen Gale, this could not have come at a better time. I really need a wiki-break. I don't feel badly about it. Although it was not my intention to violate 3RR, I'm just not good at keeping track. Anyhow, one editor who I admire a lot, , was blocked for a year. He was trying to do the right thing, but was outnumbered. I am sure that the edits of the users opposing were acting in ``good faith,`` even though they are mostly schmucks, creeps, and liars. No one can live in this world, or wiki-world, without dealing with schmucks, creeps, and liars. Its just the way things are.   `\n",
      "\n",
      "\n",
      "267798594\n",
      "False\n",
      "09:37, 1 February 2009\n",
      "\n",
      "\n",
      "269951610\n",
      "False\n",
      "NEWLINE_TOKEN:::::Yup, and obviously having a redirect from Trentino to the Province of Trento, and Trentino bold in the body of the article takes care of any other unlikely confusion.  Give some credit to our readers.    It is the same situation as was done with Bolzano-Bozen.  Also, in English we call this province Alto Adige or South Tyrol.  Both are commonly used.   Regularly BBC will interchange terms.\n",
      "\n",
      "\n",
      "272845494\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKEN== 67.239.39.8 ==NEWLINE_TOKENNEWLINE_TOKENVandalized this page please revert it\n",
      "\n",
      "\n",
      "277200841\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKENHe is a CHEATER, and the article should say that.\n",
      "\n",
      "\n",
      "306091129\n",
      "True\n",
      "NEWLINE_TOKENNEWLINE_TOKENyou stink shoo woo woo\n",
      "\n",
      "\n",
      "312354676\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKEN:I don't have the book, so I don't know if the list here is in descending order to correspond with the book, but I'm going to put it in ascending order anyway, to avoid confusion.\n",
      "\n",
      "\n",
      "312585414\n",
      "False\n",
      "`NEWLINE_TOKEN:::::::::You're selectively reading portions of the article and ignoring the rest to come to a false conclusion.  It is very clear, both in the specific context of the specific article, and the broader context of his other writing, that Stenger regards the attempt to connect quantum mechanics with consciousness, whether by Lazla, the Maharishi and the TM Movement, including Hagelin, Capra, or others as all of a piece, whether one calls it ``quantum consciousness``, ``cosmic consciousness``, or Stenger's preferred term ``quantum metaphysics``, or the term used in Wikipedia ``quantum mysticism``, and his criticism is not limited to Lanza. The argument that the Stenger reference doesn't meet WP:V is nothing but Wikilawyering. Verifiability does not mean that a reliable source needs to provide footnotes or references for statements made by the author.  You are confusing what is required of Wikipedia editors in citing reliable, verifiable sources with what is required of the authors of those sources. That is not what verifiability means.  The threshold for inclusion in Wikipedia is verifiability, not truth�that is, whether readers are able to check that material added to Wikipedia has already been published by a reliable source, not whether we think it is true. Editors should provide a reliable source for quotations and for any material that is challenged or likely to be challenged, or the material may be removed. (Emphasis added) This paragraph is reliably sources and verifiable. Arguments to the contrary are not well-taken.    `\n",
      "\n",
      "\n",
      "327377828\n",
      "False\n",
      "`NEWLINE_TOKENNEWLINE_TOKEN== Clear ==NEWLINE_TOKENIt is abundantly clear that I will delete, without response, messages which ``are rude, incivil, combative, belligerent, assume bad faith, or are generally unpleasant.   `\n",
      "\n",
      "\n",
      "327417500\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKEN== Reverend Dunn ====NEWLINE_TOKENHe's not a priest as mentioned. He has a wife, and he's a reverend.\n",
      "\n",
      "\n",
      "327865678\n",
      "True\n",
      "You hate stupidity but for some reason your deeds are classified as such too often. NEWLINE_TOKEN   Doesn't that seem strange to you? Be careful what you hate. It is not good to start hating yourself.   NEWLINE_TOKENNEWLINE_TOKEN\n",
      "\n",
      "\n",
      "331065849\n",
      "False\n",
      "`NEWLINE_TOKENNEWLINE_TOKEN:::::Rursus, Wikipedia is not paper, and there is no natural limit to articles.  Limits are just guidelines.  I think it is easonable that articles on more complex and controversial topics will be longer than other articles; the article on ``race`` will be longer than the article on ``igneous rocks`` for example.  Our articles are organized with clear section headers so people can skip stuff they are not interested in.  But given the wide range of misunderstandings about race, I think there is a lot of value to one article that explores the different facets in detail.  Obviously I am all for trimming fat, or redundancies. But most people simply cannot understand points most scientists take for granted unless they read aout the research by both population geneticists and sociologists.  I see a lot of value in putting this material in the same article.  To separate it is to confirm a widespread misbelief, that sociologists and biologists do not agree with one another or have mutually reenforcing views.  And I really hesitate to use summary style, because people new to the topic just will not understand a summary of complex research. It needs to be spelled out clearly, however many words that takes.    |   `\n",
      "\n",
      "\n",
      "331911785\n",
      "False\n",
      "`NEWLINE_TOKEN:::I just have one thing to say in my defence before I take Upstater's advice and let things slide from now on. Hippo can wikihound me, Hippo can call my editing ``crap`` at AN/I, insult opinions and editing and comments various times, and call another user's opinion ``moronic``  but I call him out for being a stalker... that's over the line? Is that the precedent here? Get stalked- nothing happens; call someone a stalker- get blocked. Id rather have been taken to AN/I where I could defend myself, there was no ``warning`` there was no discussion, no asking for ``my side``. So... he can wikihound me again and worse and I cant do anything at all, I bring him to AN/I and all he has to do is point to this and say ``Camelbinky called me a stalker, block him``. Because of this block every edit of mine from now on is fair game for Hippo to do what he used to do but on a larger scale with impunity and immunity. That really seems fair.  `\n",
      "\n",
      "\n",
      "336906991\n",
      "False\n",
      "`NEWLINE_TOKEN:::::::December, you should be watching my mistakes and learn from them. Trust me, it;s not fun going through this.  `\n",
      "\n",
      "\n",
      "338293598\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKEN==Tenderloin Article==NEWLINE_TOKENThanks for the compliment. As far as posting wikipedia policy, I meant it for past, current, and future editors to that page. Looking at that talk page and history of the article, its mind-blowing that people were able to get away with such policy violations. I will continue to keep an eye for such violations.NEWLINE_TOKEN\n",
      "\n",
      "\n",
      "347302492\n",
      "True\n",
      "`NEWLINE_TOKEN:This is so funny. Sanam here talking about ``methods encouraged by wikipedia``. Your tricks are out Sanam. Find some other place to vandalize.   `\n",
      "\n",
      "\n",
      "352345723\n",
      "False\n",
      "NEWLINE_TOKEN::Email me \\/\n",
      "\n",
      "\n",
      "361327736\n",
      "False\n",
      "NEWLINE_TOKEN:::::I think so. There are a couple websites who claim North Korea sabotaged the rig as well.\n",
      "\n",
      "\n",
      "370677212\n",
      "False\n",
      "`NEWLINE_TOKEN:If you care to copy the web page address here, I will add it for you to show how it's done '''''' `\n",
      "\n",
      "\n",
      "371725960\n",
      "True\n",
      "NEWLINE_TOKENNEWLINE_TOKEN== You piece of chickenshit cunt ==NEWLINE_TOKENNEWLINE_TOKENI'm going to have my way with the zero hedge article punk, and if you get in my way I'm going to rape your user page motherfucker.\n",
      "\n",
      "\n",
      "373801814\n",
      "False\n",
      "NEWLINE_TOKEN::Ahhh, the meatpuppetry acting. This should be enough after the clerk check.\n",
      "\n",
      "\n",
      "380308010\n",
      "False\n",
      "`NEWLINE_TOKEN:I think you mean delete, not delite. /  `\n",
      "\n",
      "\n",
      "385439315\n",
      "True\n",
      "NEWLINE_TOKENNEWLINE_TOKENYeah 9 11 was carried out by 19 cave dwelling Muslims who are openly funded by  CIA. Even the Jundallaah terrorist leader admitted it. Wikipedia is for fact suppressing fagots like yourself.\n",
      "\n",
      "\n",
      "393698861\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKEN== You Won! ==NEWLINE_TOKENNEWLINE_TOKENPlease pick up your prize at 33 West Bone Ave, Green Bay, Wisconsin. Thank you.\n",
      "\n",
      "\n",
      "403198613\n",
      "True\n",
      "Hello, do you have a real job? Or is your life so F.U that you gain solace from editing wiki all day with your inane drivel? Get a real job that pays!\n",
      "\n",
      "\n",
      "411846506\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKENPS I see your home due to snow.\n",
      "\n",
      "\n",
      "425750555\n",
      "False\n",
      "`NEWLINE_TOKEN::::Thats fine, and to be honest I understand you confusion. I had to say that to him, warn him, bur thats done now and I want to let it go. It gives me the creeos by now, and I have no problem with being blocked, at all.  `\n",
      "\n",
      "\n",
      "426772875\n",
      "False\n",
      "I picked up the name Kurt Adkins somewhere in wickopedia but i cannot remember where - but who cares - if i am wrong in a discussion then no harm and certainly no harrassment had been caused -unless there are larger issues that you cannot disclose.\n",
      "\n",
      "\n",
      "431330131\n",
      "True\n",
      "NEWLINE_TOKENYOU GUYS ARE FUCKIN CRAZY YOU STUPID SHIT LICK YOUR OWN PIMPLY FAT UGLY BUM!!!! YOU ARE CRAZY YOU ALL GAYS AND FAGGOTS IF NOT MALE THAN LESBIAN I KNOW YOU GONNA DELETE ME OR DO YOUR STUPID BLOCK THING TO ME NOW BUT I DON'T CARE YOU ARE SINGLE AND HAVE THE WEIRDEST BOOBS OKAY I HATE YOU BITCHES!\n",
      "\n",
      "\n",
      "438983383\n",
      "False\n",
      "NEWLINE_TOKEN:::Information should only be included if it is worthwhile, not merely because it is verifiable. If there is not much of note to mention, then leave it with little mentioned.\n",
      "\n",
      "\n",
      "441239817\n",
      "False\n",
      "`NEWLINE_TOKENNEWLINE_TOKEN:::::::::I'm doing something over on WWE Championship and the champions' list to make a point.  If what you believe I am proposing here with Daniel Bryan is WP:Crystal, then the entire current WWE Championship scenario is also WP:Crystal, and we don't even have a verified idea as to who is WWE Champion is or what the valid lineage is at all.  For the same reason, is the ``vacation`` and tournament similarly WP:Crystal, especially given some very real storyline questions which were never really addressed?  This is why you default back to what I stated when I quoted you Wikipedia's own ``not a crystal ball`` situation.  Under your guise of WP:Crystal, not only do you reverse any mention of Miz/Mysterio, you must also reverse everything which was announced on the 7/18 RAW, including the title strippage!  But then is CM Punk even the champion at all, given several factors in the storyline going back to the ``worked shoot`` promo?  If you want to open a WP:Crystal can of worms, then pro wrestling is a very bad place to be following announced events here on Wikipedia!  You would basically have to accuse me openly of being unable to read simple English to come to any other conclusion!   `\n",
      "\n",
      "\n",
      "445253228\n",
      "False\n",
      "`I have to agree. The whole concept doesn't make sense. How do you define a game, especially when it has no players? NEWLINE_TOKENNEWLINE_TOKENThe first sentence defines a zero player game as a game without any human players (no citation). The second sentence defines it as a game played by artificial intelligence. Whether the player is human or machine, there's still at least one player. NEWLINE_TOKENNEWLINE_TOKENAnd if the Game of Life has no players, is it really a game? Or is it an algorithm or mathematical ``thing``? If you grow a flower or a crystal, its not a game. So when you grow the ``Game of Life``, is it really a game? NEWLINE_TOKENNEWLINE_TOKENOr if one considers the programmer/user as the player, since they will be the one to pick initial board, then it's not really a zero player game.NEWLINE_TOKENNEWLINE_TOKEN`\n",
      "\n",
      "\n",
      "454435700\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKEN== Additions to the Gantofta IF page==NEWLINE_TOKENNEWLINE_TOKENI have created a page for Gantofta IF as a stub that can now be developed by those with a far greater knowledge of Gantofta IF football than myself.  It would be great to see articles and photos added to the page covering for example the club headquarters, football ground, team photograph, historic facts and much more.NEWLINE_TOKENNEWLINE_TOKEN (Finnish Gas )\n",
      "\n",
      "\n",
      "468032222\n",
      "False\n",
      "`NEWLINE_TOKENNEWLINE_TOKEN== Picture Sources ==NEWLINE_TOKENNEWLINE_TOKENWhat was meant by ``no sources given for these restorations, not acceptable for FA``?  Is the references I used for making the pictures in the first place, or where the pictures came from?  `\n",
      "\n",
      "\n",
      "492350139\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKENOK, I think I've dealt with most of the issues you mentioned. I've expanded the description, and added a Conservation section. I will re-work the lead when everything else is sorted out, but before I do, is there anything else you want me to look at? (The article has been distinctly improved by this review, so I'm happy for you to suggest more additions.)\n",
      "\n",
      "\n",
      "493018998\n",
      "False\n",
      "`NEWLINE_TOKEN::Sahih Hadith are only second in authority after Qur'an. This article is about Islam and domestic violence and they are Islamic sources..I have not picked them up from blogs. Stop reverting this.  `\n",
      "\n",
      "\n",
      "499086717\n",
      "False\n",
      "`NEWLINE_TOKEN::::Furthermore, you are incorrect regarding the UNICEF number being absolute. I quote the Guardian ``In this UNICEF research child poverty is calculated by looking at the percentage of children living in homes with equivalent incomes below 50% of the nation median.``.   `\n",
      "\n",
      "\n",
      "499529394\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKEN== Herv� Descottes ==NEWLINE_TOKENNEWLINE_TOKENI just closed your AfD on Herv� Descottes. You were the only person who participated in that discussion, which I don't really understand. With the thousands of people who are registered on this website, I would have thought that at least one other person would have an opinion on the subject. In any event, the article is preserved. Thanks.\n",
      "\n",
      "\n",
      "518204933\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKEN== posthumous adoption ==NEWLINE_TOKENNEWLINE_TOKENUh, this means that he was adopted by Caesar after his death...NEWLINE_TOKENNEWLINE_TOKENCaesar died before Augustus. It's a bit hard to understand how Caesar could take actions after his own death. And since Caesar died before Augustus, it would appear that Caesar did not adopt Augustus after Augustus' death. This needs some clarification.\n",
      "\n",
      "\n",
      "532617145\n",
      "False\n",
      "`NEWLINE_TOKEN:::The MMAWeekly article says that Silva is ``Highly regarded as one of the favorites to win this entire tournament coming in``. MMAWeekly is just fine. As for the part about what Silva said, you should check out the source for it.   `\n",
      "\n",
      "\n",
      "561103993\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKEN== Some faecal matter ==NEWLINE_TOKENNEWLINE_TOKENHi, Mathonius. I am no expert on human faeces like yourself but I was wondering why content like this is allowed on Toilet paper but not in the Anal cleansing section of Human feces: Elsewhere, wealthy people wiped themselves with wool, lace or hemp, while less wealthy people used their hand when defecating into rivers, or cleaned themselves with various materials such as rags, wood shavings, leaves, grass, hay, stone, sand, moss, water, snow, maize, ferns, may apple plant husks, fruit skins, or seashells, and corncobs, depending upon the country and weather conditions or social customs. In Ancient Rome, a sponge on a stick was commonly used, and, after usage, placed back in a bucket of saltwater. Several talmudic sources indicating ancient Jewish practice refer to the use of small pebbles, often carried in a special bag, and also to the use of dry grass and of the smooth edges of broken pottery jugs (e.g., Shabbat 81a, 82a, Yevamot 59b). These are all cited in the classic Biblical and Talmudic Medicine by the German physician Julius Preuss (Eng. trans. Sanhedrin Press, 1978).NEWLINE_TOKENNEWLINE_TOKENIdeas?\n",
      "\n",
      "\n",
      "572780184\n",
      "False\n",
      "NEWLINE_TOKEN: I've unprotected the image; according to the log entry, it was protected because it was to feature on the main page at one time, and Crisco probably just accidentally forgot to set an end date for the protection. (Indefinite is the default protection length.) �\n",
      "\n",
      "\n",
      "574217639\n",
      "False\n",
      "`NEWLINE_TOKENNEWLINE_TOKEN== there is more.... ==NEWLINE_TOKENNEWLINE_TOKENthe turkish word for calf - the muscle on your leg - is baldyr.NEWLINE_TOKENNEWLINE_TOKENbaldyr is a norse god.NEWLINE_TOKENNEWLINE_TOKENamanbirNEWLINE_TOKENNEWLINE_TOKEN  NEWLINE_TOKEN:No, Baldr is -)   NEWLINE_TOKENNEWLINE_TOKEN:: the edda, whiich i take to be the source of norse mythology is the fictional account of The Asa Monarchy of Danmark-Sweden-Norway. This Asa Monarchy may have been established in the period 600-300 bc. They are from the adriatic/aegean and they brought their soldiers, craftsmen and priests. THOR is from THRACE, present Bulgaria. Harald Harald, a gypsy ?   )  Amanbir.   NEWLINE_TOKENNEWLINE_TOKEN:::I really should improve Prologue (Prose Edda) to help people laboring under this kind of misapprehension. I'm afraid you're showing great ignorance.   NEWLINE_TOKENNEWLINE_TOKENTHE NORSE SHOULD NOT BE ACADEMICS. THEY ARE NOT FIT.NEWLINE_TOKENNEWLINE_TOKENmy my     the war of all wars      The Trojan @ Norse .   NEWLINE_TOKENNEWLINE_TOKENWell, What Can I Say - Stand Ground, Grease, Left To Move First, By 3. Wait For Charge.NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENAmanbir Singh Grewal NEWLINE_TOKENNEWLINE_TOKENGermaniaNEWLINE_TOKENNEWLINE_TOKEN  � Preceding unsigned comment added by    `\n",
      "\n",
      "\n",
      "581229632\n",
      "False\n",
      "There's something else to keep in mind  as with all people with social problems, he lets things linger and carry over and use it as an excuse a long time down the road - he remembers from a few months ago how I didn't let him intimidate me THEN, and now he is still trying to do it, so, since he's realized that after 2 months I'm STILL not allowing him to intimidate me, he can't stand it, and he lashes out.NEWLINE_TOKENHe's going to be embarrased at that other page  the admins are going to see through his BS and realize that for the first time, this is someone who's standing up to him. He's not tough.   NEWLINE_TOKENNEWLINE_TOKEN\n",
      "\n",
      "\n",
      "584226824\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKEN:Yeah, I noticed that too. For the report cited, I've switched to indicate Nitze's membership of it, i.e. membership of the Survey in Japan (he wasn't chairman).\n",
      "\n",
      "\n",
      "588279176\n",
      "False\n",
      "`NEWLINE_TOKENNEWLINE_TOKEN:AS it  happens I do think this article has become biased by the one-sided editing of Ozhistory, but these ``anonymous`` rants are not going to solve anything. By the way an argument from authority is not falacious (though some forms of it can be). It's perfectly valid. In any case, Wikipedia is supposed to be summarising the views of authorities, which is quite different, so in fact your a=own argument is a perfect example of a strawman.   `\n",
      "\n",
      "\n",
      "603643393\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKEN== Sockpuppets ==NEWLINE_TOKENNEWLINE_TOKENInstead of engaging in potentially endless edit wars with clearly sockpuppets of , I suggest you help me out finding diffs for their behaviour that are very similar to User:Ichek. They're all currently undergoing investigation at Wikipedia:Sockpuppet investigations/Ichek, where an admin has asked me to provide diffs for their similarity in behaviour.\n",
      "\n",
      "\n",
      "609293101\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKENThe yuca page over the previous disambig looks good to me.\n",
      "\n",
      "\n",
      "613463716\n",
      "False\n",
      "`NEWLINE_TOKENNEWLINE_TOKEN:: kid, do you understand what the word ``may`` in English means? It does NOT mean ``must``. It means it could happen or not. It is better that it does not. Stop vandalising. NEWLINE_TOKENNEWLINE_TOKEN:: When I have time I will go through all Serbian family names that redirect to a single individual and remove that stupidity (forced redirect link) and design a brief description that eaxch of those is a family name, such as for e.g. the name ``Smith`` in English.`\n",
      "\n",
      "\n",
      "623053871\n",
      "False\n",
      "`NEWLINE_TOKEN::: If you really think it's likely, speedy close it per WP:SNOW.    `\n",
      "\n",
      "\n",
      "632154994\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKEN:Firstly, misspelling the names of the users you want to be blocked is not helpful. Secondly, the claim that Malaysia is using B52s is pretty ridiculous. Thirdly, you're engaged in sockpuppetry, for which I have blocked this account. You can request your  to be unblocked, but you should read the WP:Guide to appealing blocks first, and to be blunt, given your past conduct, I don't see how unblocking you would benefit the encyclopedia.\n",
      "\n",
      "\n",
      "633013499\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKEN== Legends end date issue ==NEWLINE_TOKENNEWLINE_TOKENRJaguar3, there's an anon under the IP of 76.19.217.41, claiming Legends end date was on December 29, 1995, according to LegendsWikia. That definitely can't be it, and I was wondering if you can help so I won't get into a war with the person, who could possibly continue. I tried once and then another.\n",
      "\n",
      "\n",
      "644844910\n",
      "False\n",
      "REDIRECT Talk:Jack Edwards (British politician)NEWLINE_TOKEN\n",
      "\n",
      "\n",
      "661898530\n",
      "False\n",
      "NEWLINE_TOKEN:::::Says flinging babies into the Ganges was commonplace\n",
      "\n",
      "\n",
      "664555073\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENhenry lee lucas was my dad im pretty sure i know the information better than you do.\n",
      "\n",
      "\n",
      "666780815\n",
      "False\n",
      "Moreover, the Mongols are a fairly homogeneous group of people.\n",
      "\n",
      "\n",
      "668951831\n",
      "True\n",
      "NEWLINE_TOKENNEWLINE_TOKEN== Cassianto ==NEWLINE_TOKENNEWLINE_TOKENHi. I received an email from someone asking me to comment on this page about guys called Cassianto and Shro Cat. The email said you're being harassed. Never heard of Shro Cat, but Cassianto was some pitiful, obsequious little cunt who implied that I ought to show respect for someone who writes crappy featured articles. I told Cassianto to FO; I told him not to contact me again. The creep came back once. I ignored it. NEWLINE_TOKENNEWLINE_TOKENTo be frank, you need to learn how to deal with this. Forums and online communities are full of creeps, social inadequates, born losers, stalkers and mentally unstable zeros. Tell them to FO and ignore them. NEWLINE_TOKENNEWLINE_TOKENRespectfully, I don't want any further emails (or comments on my talk page) about this. I'm really not interested. Ignore this piece of shit Cassianto and it'll leave you alone.\n",
      "\n",
      "\n",
      "669181324\n",
      "True\n",
      "You do more damage than the vandals.\n",
      "\n",
      "\n",
      "669961038\n",
      "False\n",
      "REDIRECT Talk:Buckskin Frank LeslieNEWLINE_TOKEN\n",
      "\n",
      "\n",
      "679348509\n",
      "False\n",
      "NEWLINE_TOKENNEWLINE_TOKEN: I can't find any source in English that says more about him other than the fact that he's a deputy minister of Iran, some sources do state his views though. I wouldn't mind if you delete the article or nominate it for deletion. Thanks you and best regards,\n",
      "\n",
      "\n",
      "690736974\n",
      "False\n",
      "`NEWLINE_TOKENNEWLINE_TOKENNote - what Wikidemon describes as ``low level mud-slinging nonsense``, that was ``hardly reported in the press``, happened to be rather widely covered (hello !) by, among others in the mainstream media: the New York Times, Washington Post, USA Today, CNN, and NBC News, as well as by People Magazine and Politico.If you don't consider those reliable and noteworthy sources by whatever your standards are, then it puzzles me what it is exactly that you might deem a valid source (??) in your universe. -     (And, BTW, the rather apparent and thinly disguised pro-Hillary biases -  - of those commenting here, would really best be tempered just a tad, and held in check a wee bit, in accord with Wikipedia:NPOV policies, when you are editing political articles.)`\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_comments = text_df\\\n",
    "    .select('rev_id', 'is_attack', 'comment')\\\n",
    "    .sample(fraction=1/1000)\\\n",
    "    .toPandas()\n",
    "\n",
    "for _, sample_comment in sample_comments.iterrows():\n",
    "    rev_id, is_attack, comment = sample_comment\n",
    "    \n",
    "    print(rev_id)\n",
    "    print(is_attack)\n",
    "    print(comment)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select and filter data set (only training articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31253"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### SELCT ONLY REV_ID AND COMMENT FIELDS, AND FILTER FOR TRAINING DATA AND ARTILES ONLY\n",
    "sqlStatement = \"\"\" SELECT rev_id, comment \n",
    "            FROM text_table \n",
    "            where ns = 'article' and split = 'train' \"\"\"\n",
    "text_filtered_df = spark.sql(sqlStatement)\n",
    "\n",
    "## CACHE NEW DATAFRAME IN MEMORY AND CREATE TEMPORARY TABLE\n",
    "text_filtered_df.cache(); \n",
    "text_filtered_df.createOrReplaceTempView(\"text_filtered_table\")\n",
    "\n",
    "## COUNT NUMBER OF ROWS IN DATAFRAME AFTER FILTERING\n",
    "text_filtered_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View some filtered texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48528526\n",
      "NEWLINE_TOKENNEWLINE_TOKEN== The new picture cinches itGood work ==NEWLINE_TOKENNEWLINE_TOKENThe new picture of Lee Harvey Oswald holding a rifle and other incriminating evidence is much better than the similar one that was in the article.  See, Exhibit 746-A from the Warren Commission.NEWLINE_TOKENNEWLINE_TOKENThe new picture is much darker and conceals the apparent  fabrication of the photo as complained about by Oswald before he was shot. NEWLINE_TOKENNEWLINE_TOKENWe have to keep in mind that the fabrication of photographs back in 1963 was still rather primitive.  The similar pictures that the Warren Commission had available are either blow ups of the picture (which are too revealing or have disastrous results), or the print is not dark enough to conceal the cut and paste job on the face of which Oswald  complained.  See, for example Warren Commission Ex 746-C with the face pasted on at the level of the chin. NEWLINE_TOKENNEWLINE_TOKENIt was also a wise choice not to use Exhibit 749 because it has that embarrassing oversight where someone drew in what appeared to be the butt of the gun stock for another photograph and re-used it with the triangular piece of gun stock still drawn in. (See, third picket from Oswald's leg).NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENIt actually might be better just to describe the pictures and not reproduce. If the reader looks at one picture the reader might look at the rest.NEWLINE_TOKENNEWLINE_TOKEN\n",
      "\n",
      "\n",
      "55413100\n",
      "`NEWLINE_TOKENNEWLINE_TOKENWe got married in Sweden in 1982. I was a UK national and my wife Hungarian. We had to satisfy the authorities that the laws of our respective countries did not stop us marrying. So the reference to  ``This was a result of an order from the Ministry for Foreign Affairs (Utrikesdepartementet), saying that a Hague Convention of 1902 required its signatories to enforce other countries' marriage laws on those countries' citizens.`` seems to have still then been in force.`\n",
      "\n",
      "\n",
      "66841245\n",
      "NEWLINE_TOKENNEWLINE_TOKEN== subhash bose ==NEWLINE_TOKENNEWLINE_TOKENis a confirmed sockpuppeteer. He is goes around with a variety of names and vandalises pages related to dalits and caste and fills them up with Hindu propoganda material. I am reversing all his edits\n",
      "\n",
      "\n",
      "68716396\n",
      "NEWLINE_TOKEN:::Okay, I've tidied the references section, and seperated the Midtown High & Bugle listings on the supporting cast section into individual characters.\n",
      "\n",
      "\n",
      "77429453\n",
      "NEWLINE_TOKENNEWLINE_TOKEN== Eddie Brock Jr.? ==NEWLINE_TOKENNEWLINE_TOKENIs it actually verified that this is what the character is called in the movie?  Otherwise it seems based on the movie character's similarity to Ultimate Venom.\n",
      "\n",
      "\n",
      "80425068\n",
      "yesbadboy1 plese contact him please\n",
      "\n",
      "\n",
      "94258816\n",
      "NEWLINE_TOKEN::: I agree with Ali. The [[Encyclopaedia of Islam] states that N. Sims.Williams' researches partly support the old claims of Enoki, that the Bactrians indeed used Bactrian. However, they also reveal that Bactrian was not the native tongue of the Hephthalites - though still pointing to the theoriy that their native tongue was an East Iranian language, infiltrated with many Turkic and/or Mongolian words.\n",
      "\n",
      "\n",
      "110503043\n",
      "My two cents. Spoilers are fail.  NEWLINE_TOKENNEWLINE_TOKEN\n",
      "\n",
      "\n",
      "128630889\n",
      "NEWLINE_TOKENNEWLINE_TOKEN== Genre is Heavy Metal, not Hard rock. ==NEWLINE_TOKENNEWLINE_TOKENAvenged Sevenfold is a heavy metal band so stop fucking change its genre. If you're so stuck up by older generation of heavy metal bands and can't accept newer and younger heavy metal bands then fuck off. God damn old faggots keep changing the genre to hard rock over and over again, it's so fucking annoying.\n",
      "\n",
      "\n",
      "128962663\n",
      "`== External Link additions ==NEWLINE_TOKENNEWLINE_TOKENPlease could I add the following weblink to the ``external links`` section of the spiderman 3 pages.NEWLINE_TOKENhttp://www.gruntmedia.co.uk/albums/show/112  London film premiere photos gruntmedia.co.uk NEWLINE_TOKENNEWLINE_TOKEN`\n",
      "\n",
      "\n",
      "148166022\n",
      "Why is this the only episode to have a seperate page?\n",
      "\n",
      "\n",
      "151746040\n",
      "NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENNot to mention, he's a nobody. He's his biggest fan - just look at his Wikipedia page history.\n",
      "\n",
      "\n",
      "179194673\n",
      "`The Twelve Days of Christmas ==    NEWLINE_TOKENI spotted a variant on eBay that showed vol.12 ``The Twelve Days of Christmas`` with the vertical white label texture, so I'm going to list down that volume as December 24, 1991 because they were still using that tape master back in 1991. There's nothing much about it, considering it's holiday release, that means it has just the 1984 FBI warnings & 1986 HV logo at the beginning before the film, but at the end is that Christmas promo for other Christmas films, but doesn't metion the film. It's kinda' like Very Merry Christmas Songs.  NEWLINE_TOKENNEWLINE_TOKEN== `\n",
      "\n",
      "\n",
      "192743956\n",
      "Worst. Article. Ever.NEWLINE_TOKENThis article is the worst I've seen in a long time. It should be rewritten by someone who knows what they are talking about eg. actually gynocologists. The photo should be removed as it is not representative of normal women. It seems very small and I wonder if it is even an adult woman as it doesnt even have any pubic hair at all. Failing that more photos of what normal/natural more average women look like should be added. Otherwise you are going to get teenagers coming on here hoping to be reassured they are normal and finding this crap.  �Preceding unsigned comment added by    NEWLINE_TOKENNEWLINE_TOKEN\n",
      "\n",
      "\n",
      "215955572\n",
      "NEWLINE_TOKEN:::Great! I was scratching my head a bit over those colliers - charcolliers seem obvious, now you mention them! There will be a ref somewhere I suppose - I've got a copy of Ekwall's English Place-Names, but Colliers Wood isn't listed. Presumably it's listed in the English Place-Name Society's Surrey volume, but I can't get sight of it for annoying, personal reasons - hey ho! Cheers.\n",
      "\n",
      "\n",
      "254335429\n",
      "NEWLINE_TOKEN::Part of the problem is the cast.  The even though characters leave during a series, they're part of the cast for some part of the series, and really should remain listed until the next series starts.  That's my understanding of the guidelines for longer-running series (such as ER or Law and Order in the US), and which I think would apply here.\n",
      "\n",
      "\n",
      "294554009\n",
      "NEWLINE_TOKENNEWLINE_TOKENI have built on your edits, and included several votes I did not have in my version.  However, there are two major changes you will note:NEWLINE_TOKENNEWLINE_TOKEN1) You had too many categories, and this made for a choppy article.  You almost had a header and then one sentence.  I have grouped them into larger headers.NEWLINE_TOKEN2) You had numerous places where you use derogatory language or tone.  I have removed those.NEWLINE_TOKENNEWLINE_TOKENPlease let me know what specifically I left out that you would like to include, or if you believe there is language that is too rosy about Debicella.\n",
      "\n",
      "\n",
      "318244397\n",
      "Caelum?==NEWLINE_TOKENA difference between the title and the main body of text.\n",
      "\n",
      "\n",
      "337471173\n",
      "NEWLINE_TOKENNEWLINE_TOKEN== Title stylization ==NEWLINE_TOKENNEWLINE_TOKENIsn't there a convention on Wikipedia that characters that aren't pronounced be left out?\n",
      "\n",
      "\n",
      "344263132\n",
      "NEWLINE_TOKENNEWLINE_TOKENYou have not demonstrated the unreliability of http://www.gatineauparc.ca/home_en.html. In fact you are expressing a personal view that it is not reliable. It provides sources and documents you will find nowhere else. That is why it should be included as a reference. NEWLINE_TOKENNEWLINE_TOKENBesides, you mention the organization in the article and do not provide any reference to it. So I suggest you either delete the unsupported reference to the GPPC and NWPL, or add a refererence to http://www.gatineauparc.ca/home_en.html.NEWLINE_TOKENNEWLINE_TOKENYou are suppressing reliable and verifiable information in support of a Wikipedia article. This should be denounced as a violation of the letter and spirit of encylopedic knowledge.l\n",
      "\n",
      "\n",
      "358267544\n",
      "And finally, (with regard to �ad hominem attacks�): Quoting you:  You should know that on Wikipedia, you won�t get anywhere with that sort of attitude and may well be blocked. Please respect the fact that this article has existed since 2004; other editors have other ideas too. I just reverted some I.P. editor, who, apparently not impressed by your arguments (or finding your contributions unsuitable) deleted the whole bit you added. And, as I sense might be starting to dawn on you, other editors have ideas for the scope of its content that vary from yours. If you find some factual errors, please feel free to correct them. If you see assertions that need support, please cite them. But please don�t presume to come here and delete what has been stable for years and pronounce what you believe to be the proper scope of Solid modeling and how it is no more than a treatise on the mathematical underpinnings.\n",
      "\n",
      "\n",
      "367510633\n",
      "NEWLINE_TOKEN:::::: You say as something changed from beginning? You took side in this dispute, then threaten me to block me, then you continuously threaten to block me? What you have demonstrated? taking sides?\n",
      "\n",
      "\n",
      "371449817\n",
      "- both in regards of the BNP/fascism-issue\n",
      "\n",
      "\n",
      "406291926\n",
      "`NEWLINE_TOKEN:Seems like sound logic to me.  `\n",
      "\n",
      "\n",
      "447765195\n",
      "`NEWLINE_TOKENWas the Flavian supposed to echo the Lucitania (which was torpedoed,) or the Titanic (which struck an iceberg.)  If it echoed the Titanic, it would put that part of ``Emily's Quest`` in 1912.`\n",
      "\n",
      "\n",
      "463583257\n",
      ". The GA weas six weeks ago - it tottk over six weeks ot gewt a review - little has changes in the content since than - a review so soon is undue\n",
      "\n",
      "\n",
      "495049887\n",
      "I have deleted the compete section.    -  NEWLINE_TOKENNEWLINE_TOKEN\n",
      "\n",
      "\n",
      "496068836\n",
      "NEWLINE_TOKENNEWLINE_TOKEN==REJECTED SUBMISSION==NEWLINE_TOKENFBI FOIA FILESNEWLINE_TOKENAmelia Earhart from the FBI FOIF(freedom of imformation files)NEWLINE_TOKENThe files at the link below clearly show and state that many radio operators intercepted Earhart's radio transmissions.NEWLINE_TOKEN These files on pages 49 thru to 54 establish that Earhart landed in the Marshall Islands and was taken prisoner by the Japanese. After reading the files it is obvious that Earhart and Noonan were both alive and had landed safely, however into or near a secret Japanese base. Due to the planes altitude the radio transmissions misled those waiting to intercept Earhart as planned. Off course far north of Howland Island, Earhart is said to have actually landed on Knox Island nearer to the Marshall Islands. This is outlined by the FBI files. The files document often repeated and frantic requests by radio operators to get FBI assistance in finding Earhart, even many years after her disappearance.  NEWLINE_TOKENHere is the FBI link: http://vault.fbi.gov/amelia-mary-earhart/amelia-mary-earhart-part-01-of-01/viewNEWLINE_TOKEN\n",
      "\n",
      "\n",
      "497520082\n",
      "`NEWLINE_TOKENNEWLINE_TOKEN====Paul's amnesia====NEWLINE_TOKENPaul, we have discussed before many times before, back in March 2011 and September 2011 It seems extraordinary that you think Wikipedia policies are dishonest, because while Dr. M�lksoo provides a valuable opinion, at the end of the day we must comply with policy. In case you have ``forgotten``  between the time you clicked my links above and this point in the text, I will re-iterate: ``reliance solely on Dr. M�lksoo's opinion is contrary to WP:TITLE policy, which instructs us not to rely on a single source, but a whole range of sources when determining an article name per WP:COMMONNAME.``   `\n",
      "\n",
      "\n",
      "544470770\n",
      "NEWLINE_TOKENNEWLINE_TOKEN== Request for comment ==NEWLINE_TOKENNEWLINE_TOKEN an incident has occurred within the church involving some type of sexual scandal. There is a discussion between the churches ip and members of Wikipedia if this  Between 1984 and 1989 John Langworthy was a youth minister at Prestonwood Baptist Church. On January 22nd, 2013, Langworthy pled guilty to five of eight felony counts of gratification of lust against young boys, receiving a suspended sentence of 50 years. He was also required to register as a sex offender. The offences occurred at Morrison Heights Baptist Church in Clinton, MS.[11] It was reported that Langworthy also admitted, in a pulpit confession, to prior sex offenses at Prestonwood Baptist Church. Some of the alleged victims made complaints to Prestonwood Church at the time, which were dealt with internally by church officials.[12] There are now allegations that Prestonwood Baptist Church covered up Langworthy's offenses by failing to report them to the proper authorities. [11]NEWLINE_TOKENShould be in the article or not. Please refer to the discussion above.\n",
      "\n",
      "\n",
      "667070472\n",
      "NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKEN:: Is this what you wanted to show?\n",
      "\n",
      "\n",
      "675008758\n",
      "Consensus is not a vote. I am aiming to bolster stuff by checking up for more recent sources, which I'd prefer to do rather than tear things down. I've already found some decent sources that support a fair amount of Panikkar's stuff about spirit worship etc, and even a source that allows the opening statement about a putative Naga connection to be retained. I am not going to be bullied into ripping up this article, especially given its history with regard to disruption from members of the Nair community and their sockpuppets etc. -   NEWLINE_TOKENNEWLINE_TOKEN\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_comments = text_filtered_df\\\n",
    "    .select('rev_id', 'comment')\\\n",
    "    .sample(fraction=1/1000).\\\n",
    "    toPandas()\n",
    "\n",
    "for _, sample_comment in sample_comments.iterrows():\n",
    "    rev_id, comment = sample_comment\n",
    "    \n",
    "    print(rev_id)\n",
    "    print(comment)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowercase COMMENT and remove some irrelevant words and punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>this is not creative  those are the dictionary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44816</td>\n",
       "      <td>the term standard model is itself less npov t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49851</td>\n",
       "      <td>true or false the situation as of march 2002 w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93890</td>\n",
       "      <td>this page will need disambiguation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103624</td>\n",
       "      <td>i removed the followingall names of early poli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>128532</td>\n",
       "      <td>someone wrotemore recognizable perhaps is a ty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>133562</td>\n",
       "      <td>correct full biographical details will put dow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>138117</td>\n",
       "      <td>care should be taken to distinguish when and i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>192579</td>\n",
       "      <td>i fail to see the distinction  who better than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>249432</td>\n",
       "      <td>its great that weve found a new source of free...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id                                      comment_final\n",
       "0   37675  this is not creative  those are the dictionary...\n",
       "1   44816   the term standard model is itself less npov t...\n",
       "2   49851  true or false the situation as of march 2002 w...\n",
       "3   93890                 this page will need disambiguation\n",
       "4  103624  i removed the followingall names of early poli...\n",
       "5  128532  someone wrotemore recognizable perhaps is a ty...\n",
       "6  133562  correct full biographical details will put dow...\n",
       "7  138117  care should be taken to distinguish when and i...\n",
       "8  192579  i fail to see the distinction  who better than...\n",
       "9  249432  its great that weve found a new source of free..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_filtered_df2 = text_filtered_df.withColumn(\"comment1\", lower(col(\"comment\"))).\\\n",
    "    withColumn(\"comment2\", regexp_replace(\"comment1\", '-newline_token', \"\")).\\\n",
    "    withColumn(\"comment3\", regexp_replace(\"comment2\", 'newline_token', \"\")).\\\n",
    "    withColumn(\"comment_final\", regexp_replace(\"comment3\", '[^\\w-_ ]', \"\")).\\\n",
    "    select('rev_id', 'comment_final')\n",
    "    \n",
    "\n",
    "# SELECT ONE ROW OF DATAFRAME AFTER \n",
    "text_filtered_df2.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View some examples of `text_filtered_df2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rev_id', 'int'), ('comment_final', 'string')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_filtered_df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16904861\n",
      "i lived in the 17th century my father was a diplomat and poet i improved telescoopes and discovered moons i greatly improved the time keeping abilities of clocks by using a pendulum who am i\n",
      "\n",
      "\n",
      "32232941\n",
      "what would personally satisfy me is ideally a letter or email from someone working at adminch not something merely hosted by adminch but the main adminch people stating whether or not the motto is specified in any federal law or if it is just something used traditionally and then if its used across the entire country  youre quoting politicians now and i dont mean to inflict doubt upon you but the president of my country george w bush along with most other popular politicians i can think of here say some completely false things  they are not historians and they are usually not students of national law either - theyre just making speeches to try and keep people sated  i hope switzerlands politicians arent like the usas but i am constantly reminded by politicians worldwide of how ignorant most are \n",
      "\n",
      "\n",
      "38812651\n",
      "dude you just dont get it e \n",
      "\n",
      "\n",
      "40940735\n",
      "we have increased our knowledge since greco-roman times\n",
      "\n",
      "\n",
      "69904941\n",
      "whateurope is commonly reckoned as one of the seven continents of earth commonly reckoned no its a continent wtf  \n",
      "\n",
      "\n",
      "76717733\n",
      "this is an excellent point i have never been able to pull much up about this organization except for a few references what steps should we take  \n",
      "\n",
      "\n",
      "92669033\n",
      "it isnt about referencing the material on lostpedia more the fact that as a fan site about lost with an article on wikipedia it really should be linked to at the bottom just linking to a fan wiki which is nowhere near as accurate detailed or well policed isnt serving users well\n",
      "\n",
      "\n",
      "100479583\n",
      "i think it makes even more sense for a band like maiden to be on a list titled influential and important artists since they are both extremely influential and importnt to the progressive metal genre  \n",
      "\n",
      "\n",
      "102773964\n",
      "the pov rule does not ban the citing of pov material the rule bans the writing of pov wikipedia articles if no one could cite any pov articles no major exposes could be cited here and i dare you no pun intended to find a more thorough expose on the duke lacrosse case and exposes notwithstanding throughout wikipedia pov articles are cited and linked to in footnotes and in external links and that is permitted by the npov rule what is not permitted is the deletion of all pov linksfootnotes from one side of a disputethe constants in this revert war go beyond the vdare article the editor in question has used four different ips so far at bloomfield college in nj while following me around from article to article not just duke-related and as  noted never writing an edit summary fourth revert in five hours by suspected sockpuppet user 1301563057note that user 1301563057 just made his fourth revert in less than five hours in violation of the three-revert rule note too that user 1301563057 is a suspected sockpuppet from bloomfield college whose recent mo and history are identical touser 1301562961user 13015629134user 13015631143see whois summaries below20 january 2007according to the whois reports for 1301562961 and 13015629134 your friend is a student or employee of bloomfield college not sure if that helps but obviously its the same person   httpwsarinnetcgi-binwhoispl439 23 january 2007search results for 13015631143 new jersey higher education network njedge net-130-156-0-0-1                                   13015600 - 13015625525523 january 2007 search results for 1301563057 new jersey higher education network njedge net-130-156-0-0-1                                   13015600 - 130156255255bloomfield college njedge-bloomfield-college net-130-156-24-0-1                                   130156240 - 13015631255 arin whois database last updated 2007-01-22 1910 enter  for additional hints on searching arins whois databaseon 6 september 2006  also violated wikipedia rules by secretly deleting an entire passage by another editor not me on the talkjim_mcgreevey pagediff httpenwikipediaorgwindexphptitletalkjim_mcgreeveydiffprevoldid74166450 \n",
      "\n",
      "\n",
      "146872876\n",
      "it is true and sources were sited it will be added back soon\n",
      "\n",
      "\n",
      "206194819\n",
      "dear anonymus useror  sockpuppeti do not have a mood with you to argue look for new friends for yourselfthere  or   \n",
      "\n",
      "\n",
      "258277765\n",
      "when we currently have better sources available then why reach down into primary sources that are less reliable or unreliable in any event the controversial edit was a wpweight violation  \n",
      "\n",
      "\n",
      "274228167\n",
      "redirect talkgiu1ed3ng riu1ec1ng district\n",
      "\n",
      "\n",
      "282906849\n",
      "us citizen see obama birth certificate as many have concluded obama was never a us citizen and so ineligible to be us president and so subject to instant impeachment  removal they cite no available birth certificate which the obama campaign would never relase though claimming it existedand others feel not only us citizenship is in question but also status as possible alien  space alienseriously esp with no birth certificatehas the us foreign technology division or hanger 54 crews ever checked out obama \n",
      "\n",
      "\n",
      "308762010\n",
      "the pira campaign that we are talking about started in 1969 a few years before bloody sunday so you can hardly say it started the whole affair in motion - actually i think the whole affair was started in motion hundreds of years ago anyway this article is not about the british army its about the pira so we need to stick to their contribution to the death  injury count and as ive said elsewhere the pira have achieved very little else in the past 40 odd years than kill and maim a lot of people in ever repects by their own published aims they have failed so although we do need to agree upon accurate figures along with the sources to back them up - the information must appear in the lead for this article\n",
      "\n",
      "\n",
      "366093713\n",
      "nasser hussain should not be listed amongst the english muslims in an interview in  abritish tabloid following his selection to the english national side he was asked how he felt to be the first muslim in the english team he remarked that his father was muslim and not him nassers sister benazir a ballerina was featured in a sunday magazine she explained why she had chosen to live with a black man rather than marry him apprently her mother had asked her to choose a muslim partner and not live in sin therefore she decided to live with her boyfriend saying her mother only converted to islam after decades of being a non-muslim wife of man who was born a muslim so there you have ita sister and brother admitting to being non-muslims user moarrikh \n",
      "\n",
      "\n",
      "371875357\n",
      "editin the infobox add that the audio of pnks performance at the live at the 52nd annual grammy awards was released as a digital download on februar 1 2010source and also add that the album version of the song was released as a digital download as a single on june 15 2010sourcehere is what you should write in the release in the infobox january 31 2010 us radio  february 1 2010 digital download - live at the 52nd annual grammy awardshttpitunesapplecomusalbumglitter-in-air-live-at-52ndid353879860june 15 2010 digital downloadhttpitunesapplecomusalbumglitter-in-the-air-singleid376383757\n",
      "\n",
      "\n",
      "404411826\n",
      " criticism section i feel there should be given equal time to all the legitimate criticism of this bill  i tried to add one earlier today but it was almost immediately removed  in order to provide a balanced point of view i feel this section should be restored -\n",
      "\n",
      "\n",
      "421227461\n",
      "could the name have something to do with the pashtun tribe shirwani which became widespread throughout what is punjab and its members were in important positions throughout north india furthermore just because a name did not exist historically does not mean a culture people and their history did not exist india did not exist but hindustan did - just as bharat existed before muslims conquered and renamed it sherwani was developed in hindustan by descendants of turco-afghans mughals etc just as they also gave hindustan their adapted language food dress and customs etc these are the antecedents of pakistano\n",
      "\n",
      "\n",
      "421304781\n",
      " 29 march 2011 utc yawn   1220\n",
      "\n",
      "\n",
      "432427366\n",
      "they are supposed to document entries to the crime scene hence my use of the word undocumented i can see how a big long word like that would be easy to miss im glad this article is owned by someone like yourself with such a good eye for detail\n",
      "\n",
      "\n",
      "444983703\n",
      "redirect talkbiotin carboxyl carrier protein\n",
      "\n",
      "\n",
      "458263693\n",
      "its official wikipedia has finally gone full retard whats next goatse on the frontpage sure why not its not like this site has any standards left the human centipede is a crime against cinema and civilization that should be talked about as little as possible and you assholes put it on the front page fuck you i dont want to be reminded that this piece of shit exists\n",
      "\n",
      "\n",
      "519816175\n",
      " requested move masculine feminine u2192   this is the title in the english-speaking world not masculine feminine\n",
      "\n",
      "\n",
      "622008159\n",
      " inclusion of stitch experiments while this topic has been discussed twice before 1 2 and there was some consensus regarding not including the stitch experiments in this article due to recent editing activity i am bringing up this topic again to either re-confirm or change the consensusmy opinion is that the experiments plot descriptions from stitch should not be included here and instead have a separate article at list of experiments from stitch currently a redirect volunteers welcome to make a new list  my reason for this opinion is that while the two shows share the same general characters the original series hereby meaning the four feature films and lilo  stitch the series and the anime series are very different continuities and should be treated differently in regarding to the list this is so that readers of the descriptions will not be confused over if the descriptions pertain to either the original or anime series  additionally we as editors do not have to go through writing excessive notes and explanations where a particular experiment has very different plot histories between the two series  the use of two separate lists would mean that each experiment can be explained properly in the context of the respective series without having to explain away any continuity issues such as how they look behave or have two differentcontradictory plot histories or how some experiments like 000 appear only in ones series but not the other or on a more practical example you dont need to explain who yuna is to viewers of the original series who have no clue who she is and vice versa for lilo and nanifor precedents we have the existing list of lilo  stitch the series episodes and list of stitch episodes which handles the two series differently though admittedly i recently reverted an attempted merge of list of stitch episodes into list of lilo  stitch the series episodes that should not have been done and was not truly completed an additional precedent from other cartoon and anime series where they share the same general characters but have different continuities and different articles are the transformers articles for example list of the transformers characters and list of transformers the headmasters characters the characters in those series and all of the transformers series share character names and some traits but there separate lists for each series to keep continuity issues separatei know that the status of the article as of now is that there are some references to stitch characters in the list but the co-mingling is very limited right now with only a few experiments from stitch in the list  now is the time to make the split before more descriptions are added making a future split harder to do\n",
      "\n",
      "\n",
      "663718492\n",
      " robocop was a superhero what it appeared to be it was a superhero between cyberpunk and action reason why it is a superhero because due to robocops actions in stopping crime by upholding the law in criminal charge thats why it is a superhero\n",
      "\n",
      "\n",
      "695451727\n",
      "although i dont understand why the above comment was initially reverted even so i think it would be preferable if a fully neutral party opened the request for comment perhaps ijethrobot can be convinced to open the request or else recommend a different solution requests for comment normally only include content issues but there are surely some important content issues here which could benefit from comments to determine consensus\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_comments = text_filtered_df2\\\n",
    "    .select('rev_id', 'comment_final')\\\n",
    "    .sample(fraction=1/1000)\\\n",
    "    .toPandas()\n",
    "\n",
    "for _, sample_comment in sample_comments.iterrows():\n",
    "    rev_id, comment = sample_comment\n",
    "    \n",
    "    print(rev_id)\n",
    "    print(comment)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize COMMENT and remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+\n",
      "|rev_id|       comment_final|               words|           filtWords|\n",
      "+------+--------------------+--------------------+--------------------+\n",
      "| 37675|this is not creat...|[this, is, not, c...|[creative, , dict...|\n",
      "| 44816| the term standar...|[, the, term, sta...|[, term, standard...|\n",
      "| 49851|true or false the...|[true, or, false,...|[true, false, sit...|\n",
      "| 93890|this page will ne...|[this, page, will...|[page, need, disa...|\n",
      "|103624|i removed the fol...|[i, removed, the,...|[removed, followi...|\n",
      "+------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## DEFINE TOKENIZER AND STOPWORD REMOVER\n",
    "tokenizer = Tokenizer(inputCol=\"comment_final\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtWords\")\n",
    "\n",
    "## TRANSFORM DATASET TO TOKENIZE AND REMOVE STOPWORDS\n",
    "text_filtered_df3 = tokenizer.transform(text_filtered_df2)\n",
    "text_filtered_df4 = remover.transform(text_filtered_df3)\n",
    "\n",
    "## MATERIALIZE DATAFRAME IN MEMORY\n",
    "text_filtered_df4.cache(); text_filtered_df4.count();\n",
    "text_filtered_df4.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at one example of the effects of the transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37675 \n",
      "\n",
      "this is not creative  those are the dictionary definitions of the terms insurance and ensurance as properly applied to destruction  if you dont understand that fine legitimate criticism ill write up three man cell and bounty hunter and then it will be easy to understand why ensured and insured are different - and why both differ from assuredthe sentence you quote is absolutely neutral  you just arent familiar with the underlying theory of strike-back eg submarines as employed in nuclear warfare guiding the insurance nor likely the three man cell structure that kept the ira from being broken by the british  if thats my fault fine i can fix that to explain  but theres nothing personal or creative about itim tired of arguing with you  re the other article multi-party turns up plenty and there is more use of mutually than mutual  if i were to apply your standard id be moving mutual assured destruction to talk for not appealing to a reagan voters biases about its effectiveness and for dropping the lythere is a double standard in your edits  if it comes from some us history book like peace movement or mad as defined in 1950 you like it even if the definition is totally useless in 2002 and only of historical interest  if it makes any even-obvious connection or implication from the language chosen in multiple profession-specific terms you consider it somehow non-neutral  gandhi thinks eye for an eye describes riots death penalty and war all at once but you dont  what do you know that gandhi doesntguess what  reality is not neutral  current use of terms is slightly more controversial  neutrality requires negotiation and some willingness to learnthis is your problem not mine  you may dislike the writing fine that can be fixed  but disregarding fundamental axioms of philosphy with names that recur in multiple phrases or failing to make critical distinctions like insurance versus assurance versus ensurance which are made in one quote by an air force general in an in-context quote is just a disservice to the readerif someone comes here to research a topic like mad they want some context beyond historyif this is a history book fine its a history book  but that wasnt what it was claimed to be \n",
      "\n",
      "['this', 'is', 'not', 'creative', '', 'those', 'are', 'the', 'dictionary', 'definitions', 'of', 'the', 'terms', 'insurance', 'and', 'ensurance', 'as', 'properly', 'applied', 'to', 'destruction', '', 'if', 'you', 'dont', 'understand', 'that', 'fine', 'legitimate', 'criticism', 'ill', 'write', 'up', 'three', 'man', 'cell', 'and', 'bounty', 'hunter', 'and', 'then', 'it', 'will', 'be', 'easy', 'to', 'understand', 'why', 'ensured', 'and', 'insured', 'are', 'different', '-', 'and', 'why', 'both', 'differ', 'from', 'assuredthe', 'sentence', 'you', 'quote', 'is', 'absolutely', 'neutral', '', 'you', 'just', 'arent', 'familiar', 'with', 'the', 'underlying', 'theory', 'of', 'strike-back', 'eg', 'submarines', 'as', 'employed', 'in', 'nuclear', 'warfare', 'guiding', 'the', 'insurance', 'nor', 'likely', 'the', 'three', 'man', 'cell', 'structure', 'that', 'kept', 'the', 'ira', 'from', 'being', 'broken', 'by', 'the', 'british', '', 'if', 'thats', 'my', 'fault', 'fine', 'i', 'can', 'fix', 'that', 'to', 'explain', '', 'but', 'theres', 'nothing', 'personal', 'or', 'creative', 'about', 'itim', 'tired', 'of', 'arguing', 'with', 'you', '', 're', 'the', 'other', 'article', 'multi-party', 'turns', 'up', 'plenty', 'and', 'there', 'is', 'more', 'use', 'of', 'mutually', 'than', 'mutual', '', 'if', 'i', 'were', 'to', 'apply', 'your', 'standard', 'id', 'be', 'moving', 'mutual', 'assured', 'destruction', 'to', 'talk', 'for', 'not', 'appealing', 'to', 'a', 'reagan', 'voters', 'biases', 'about', 'its', 'effectiveness', 'and', 'for', 'dropping', 'the', 'lythere', 'is', 'a', 'double', 'standard', 'in', 'your', 'edits', '', 'if', 'it', 'comes', 'from', 'some', 'us', 'history', 'book', 'like', 'peace', 'movement', 'or', 'mad', 'as', 'defined', 'in', '1950', 'you', 'like', 'it', 'even', 'if', 'the', 'definition', 'is', 'totally', 'useless', 'in', '2002', 'and', 'only', 'of', 'historical', 'interest', '', 'if', 'it', 'makes', 'any', 'even-obvious', 'connection', 'or', 'implication', 'from', 'the', 'language', 'chosen', 'in', 'multiple', 'profession-specific', 'terms', 'you', 'consider', 'it', 'somehow', 'non-neutral', '', 'gandhi', 'thinks', 'eye', 'for', 'an', 'eye', 'describes', 'riots', 'death', 'penalty', 'and', 'war', 'all', 'at', 'once', 'but', 'you', 'dont', '', 'what', 'do', 'you', 'know', 'that', 'gandhi', 'doesntguess', 'what', '', 'reality', 'is', 'not', 'neutral', '', 'current', 'use', 'of', 'terms', 'is', 'slightly', 'more', 'controversial', '', 'neutrality', 'requires', 'negotiation', 'and', 'some', 'willingness', 'to', 'learnthis', 'is', 'your', 'problem', 'not', 'mine', '', 'you', 'may', 'dislike', 'the', 'writing', 'fine', 'that', 'can', 'be', 'fixed', '', 'but', 'disregarding', 'fundamental', 'axioms', 'of', 'philosphy', 'with', 'names', 'that', 'recur', 'in', 'multiple', 'phrases', 'or', 'failing', 'to', 'make', 'critical', 'distinctions', 'like', 'insurance', 'versus', 'assurance', 'versus', 'ensurance', 'which', 'are', 'made', 'in', 'one', 'quote', 'by', 'an', 'air', 'force', 'general', 'in', 'an', 'in-context', 'quote', 'is', 'just', 'a', 'disservice', 'to', 'the', 'readerif', 'someone', 'comes', 'here', 'to', 'research', 'a', 'topic', 'like', 'mad', 'they', 'want', 'some', 'context', 'beyond', 'historyif', 'this', 'is', 'a', 'history', 'book', 'fine', 'its', 'a', 'history', 'book', '', 'but', 'that', 'wasnt', 'what', 'it', 'was', 'claimed', 'to', 'be'] \n",
      "\n",
      "['creative', '', 'dictionary', 'definitions', 'terms', 'insurance', 'ensurance', 'properly', 'applied', 'destruction', '', 'dont', 'understand', 'fine', 'legitimate', 'criticism', 'ill', 'write', 'three', 'man', 'cell', 'bounty', 'hunter', 'easy', 'understand', 'ensured', 'insured', 'different', '-', 'differ', 'assuredthe', 'sentence', 'quote', 'absolutely', 'neutral', '', 'arent', 'familiar', 'underlying', 'theory', 'strike-back', 'eg', 'submarines', 'employed', 'nuclear', 'warfare', 'guiding', 'insurance', 'likely', 'three', 'man', 'cell', 'structure', 'kept', 'ira', 'broken', 'british', '', 'thats', 'fault', 'fine', 'fix', 'explain', '', 'theres', 'nothing', 'personal', 'creative', 'itim', 'tired', 'arguing', '', 're', 'article', 'multi-party', 'turns', 'plenty', 'use', 'mutually', 'mutual', '', 'apply', 'standard', 'id', 'moving', 'mutual', 'assured', 'destruction', 'talk', 'appealing', 'reagan', 'voters', 'biases', 'effectiveness', 'dropping', 'lythere', 'double', 'standard', 'edits', '', 'comes', 'us', 'history', 'book', 'like', 'peace', 'movement', 'mad', 'defined', '1950', 'like', 'even', 'definition', 'totally', 'useless', '2002', 'historical', 'interest', '', 'makes', 'even-obvious', 'connection', 'implication', 'language', 'chosen', 'multiple', 'profession-specific', 'terms', 'consider', 'somehow', 'non-neutral', '', 'gandhi', 'thinks', 'eye', 'eye', 'describes', 'riots', 'death', 'penalty', 'war', 'dont', '', 'know', 'gandhi', 'doesntguess', '', 'reality', 'neutral', '', 'current', 'use', 'terms', 'slightly', 'controversial', '', 'neutrality', 'requires', 'negotiation', 'willingness', 'learnthis', 'problem', 'mine', '', 'may', 'dislike', 'writing', 'fine', 'fixed', '', 'disregarding', 'fundamental', 'axioms', 'philosphy', 'names', 'recur', 'multiple', 'phrases', 'failing', 'make', 'critical', 'distinctions', 'like', 'insurance', 'versus', 'assurance', 'versus', 'ensurance', 'made', 'one', 'quote', 'air', 'force', 'general', 'in-context', 'quote', 'disservice', 'readerif', 'someone', 'comes', 'research', 'topic', 'like', 'mad', 'want', 'context', 'beyond', 'historyif', 'history', 'book', 'fine', 'history', 'book', '', 'wasnt', 'claimed'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _, (rev_id, comment_final, words, filtered_words) in text_filtered_df4.limit(1).toPandas().iterrows():\n",
    "    print(rev_id, '\\n')\n",
    "    print(comment_final, '\\n')\n",
    "    print(words, '\\n')\n",
    "    print(filtered_words, '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE AND RUN WORD2VEC ON COMMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLlib Word2Vec parameters: https://spark.apache.org/docs/2.2.0/api/scala/index.html#org.apache.spark.mllib.feature.Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 42.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = None\n",
    "window_size = 5\n",
    "vector_size = 50\n",
    "min_count = 5\n",
    "\n",
    "## DEFINE WORD2VEC TRANSFORMER\n",
    "word2Vec = Word2Vec(windowSize = window_size, vectorSize = vector_size, minCount = min_count, inputCol=\"filtWords\", outputCol=\"result\")\n",
    "\n",
    "## FIT TRANSFORMER TO GENERATE FEATURES\n",
    "model = word2Vec.fit(text_filtered_df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine some words, and other words close to them from these feature neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bad</td>\n",
       "      <td>0.753015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>assuming</td>\n",
       "      <td>0.716347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wikipediaassume</td>\n",
       "      <td>0.713356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>assume</td>\n",
       "      <td>0.668017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>luck</td>\n",
       "      <td>0.665753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nice</td>\n",
       "      <td>0.635352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aesthetically</td>\n",
       "      <td>0.620942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>faith</td>\n",
       "      <td>0.613335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>displaying</td>\n",
       "      <td>0.612768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>idea</td>\n",
       "      <td>0.592278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word  similarity\n",
       "0              bad    0.753015\n",
       "1         assuming    0.716347\n",
       "2  wikipediaassume    0.713356\n",
       "3           assume    0.668017\n",
       "4             luck    0.665753\n",
       "5             nice    0.635352\n",
       "6    aesthetically    0.620942\n",
       "7            faith    0.613335\n",
       "8       displaying    0.612768\n",
       "9             idea    0.592278"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.findSynonyms(\"good\", 10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine how the vector features look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quotient</td>\n",
       "      <td>[0.0076471297070384026, -0.04095868021249771, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>incident</td>\n",
       "      <td>[0.13022679090499878, 0.01593862660229206, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>serious</td>\n",
       "      <td>[0.15074452757835388, -0.002915252698585391, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wgbh</td>\n",
       "      <td>[0.05211513116955757, -0.04079500585794449, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brink</td>\n",
       "      <td>[0.004561762325465679, -0.02744869515299797, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word                                             vector\n",
       "0  quotient  [0.0076471297070384026, -0.04095868021249771, ...\n",
       "1  incident  [0.13022679090499878, 0.01593862660229206, -0....\n",
       "2   serious  [0.15074452757835388, -0.002915252698585391, 0...\n",
       "3      wgbh  [0.05211513116955757, -0.04079500585794449, 0....\n",
       "4     brink  [0.004561762325465679, -0.02744869515299797, -..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.getVectors().limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(word='quotient', vector=DenseVector([0.0076, -0.041, -0.0114, 0.0132, 0.0201, 0.0266, -0.016, 0.0006, 0.022, 0.0165, 0.0518, -0.018, 0.0125, 0.0171, -0.0054, 0.0057, 0.0178, -0.0357, 0.0185, 0.0154, -0.0128, -0.0309, -0.0132, 0.0052, 0.0002, 0.0277, -0.0485, -0.0087, 0.0278, 0.0269, 0.0161, -0.0213, -0.0238, 0.0205, 0.0302, 0.0147, 0.0185, -0.013, 0.0103, -0.0283, 0.033, -0.0056, 0.0018, 0.0033, 0.0135, -0.004, 0.0363, 0.0033, 0.0188, -0.0048]))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_features = model.getVectors().select(\"*\")\n",
    "word2vec_features.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Spark DF to Pandas DF for output into a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quotient</td>\n",
       "      <td>[0.0076471297070384026, -0.04095868021249771, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>incident</td>\n",
       "      <td>[0.13022679090499878, 0.01593862660229206, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>serious</td>\n",
       "      <td>[0.15074452757835388, -0.002915252698585391, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word                                             vector\n",
       "0  quotient  [0.0076471297070384026, -0.04095868021249771, ...\n",
       "1  incident  [0.13022679090499878, 0.01593862660229206, -0....\n",
       "2   serious  [0.15074452757835388, -0.002915252698585391, 0..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_features_pdf = word2vec_features.toPandas()\n",
    "word2vec_features_pdf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get comment-level vectors from word-level vectors (averaging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment_final</th>\n",
       "      <th>words</th>\n",
       "      <th>filtWords</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>this is not creative  those are the dictionary...</td>\n",
       "      <td>[this, is, not, creative, , those, are, the, d...</td>\n",
       "      <td>[creative, , dictionary, definitions, terms, i...</td>\n",
       "      <td>[0.030182989328480927, 0.012006757848279516, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44816</td>\n",
       "      <td>the term standard model is itself less npov t...</td>\n",
       "      <td>[, the, term, standard, model, is, itself, les...</td>\n",
       "      <td>[, term, standard, model, less, npov, think, w...</td>\n",
       "      <td>[0.03220316725991555, 0.014052082965178276, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49851</td>\n",
       "      <td>true or false the situation as of march 2002 w...</td>\n",
       "      <td>[true, or, false, the, situation, as, of, marc...</td>\n",
       "      <td>[true, false, situation, march, 2002, saudi, p...</td>\n",
       "      <td>[-0.03033827639495333, -0.04685172076957921, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93890</td>\n",
       "      <td>this page will need disambiguation</td>\n",
       "      <td>[this, page, will, need, disambiguation]</td>\n",
       "      <td>[page, need, disambiguation]</td>\n",
       "      <td>[0.2608961910009384, 0.12312146959205468, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103624</td>\n",
       "      <td>i removed the followingall names of early poli...</td>\n",
       "      <td>[i, removed, the, followingall, names, of, ear...</td>\n",
       "      <td>[removed, followingall, names, early, polish, ...</td>\n",
       "      <td>[-0.005317525044587013, -0.011438921760969067,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id                                      comment_final  \\\n",
       "0   37675  this is not creative  those are the dictionary...   \n",
       "1   44816   the term standard model is itself less npov t...   \n",
       "2   49851  true or false the situation as of march 2002 w...   \n",
       "3   93890                 this page will need disambiguation   \n",
       "4  103624  i removed the followingall names of early poli...   \n",
       "\n",
       "                                               words  \\\n",
       "0  [this, is, not, creative, , those, are, the, d...   \n",
       "1  [, the, term, standard, model, is, itself, les...   \n",
       "2  [true, or, false, the, situation, as, of, marc...   \n",
       "3           [this, page, will, need, disambiguation]   \n",
       "4  [i, removed, the, followingall, names, of, ear...   \n",
       "\n",
       "                                           filtWords  \\\n",
       "0  [creative, , dictionary, definitions, terms, i...   \n",
       "1  [, term, standard, model, less, npov, think, w...   \n",
       "2  [true, false, situation, march, 2002, saudi, p...   \n",
       "3                       [page, need, disambiguation]   \n",
       "4  [removed, followingall, names, early, polish, ...   \n",
       "\n",
       "                                              result  \n",
       "0  [0.030182989328480927, 0.012006757848279516, 0...  \n",
       "1  [0.03220316725991555, 0.014052082965178276, 0....  \n",
       "2  [-0.03033827639495333, -0.04685172076957921, 0...  \n",
       "3  [0.2608961910009384, 0.12312146959205468, -0.0...  \n",
       "4  [-0.005317525044587013, -0.011438921760969067,...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model.transform(text_filtered_df4).limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(rev_id=37675, result=DenseVector([0.0302, 0.012, 0.0497, -0.0078, 0.0089, -0.0392, -0.05, 0.0165, 0.0116, 0.0038, -0.0489, 0.0049, 0.0609, -0.0454, -0.0167, 0.0014, 0.0254, -0.0235, -0.0266, -0.0005, 0.0015, 0.0515, -0.0206, -0.013, -0.043, -0.0051, 0.1049, 0.0307, 0.0152, -0.0201, -0.0207, 0.0208, -0.0042, 0.0342, -0.0565, 0.0539, 0.0171, -0.0085, -0.0074, 0.0609, 0.0303, 0.0503, 0.0093, 0.0377, -0.0601, -0.0096, -0.0118, 0.0388, 0.0211, -0.013])),\n",
       " Row(rev_id=44816, result=DenseVector([0.0322, 0.0141, 0.0491, 0.0069, 0.009, -0.0399, -0.0416, 0.0041, 0.01, 0.0021, -0.0651, 0.0282, 0.0706, -0.0069, 0.0012, 0.0217, 0.0426, -0.0414, -0.0073, -0.0265, 0.0327, 0.0655, -0.043, -0.0077, -0.0558, 0.0124, 0.0795, 0.0392, -0.0068, -0.0184, -0.0255, -0.0002, 0.0188, 0.0499, -0.0739, 0.0708, 0.0592, -0.0196, 0.0172, 0.049, 0.0294, 0.0503, 0.0162, 0.0268, -0.0671, -0.0173, -0.007, 0.0329, 0.022, -0.0068]))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_vectors_df = model.transform(text_filtered_df4).select('rev_id','result')\n",
    "comment_vectors_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE FEATURES in CSV file for subsequent steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to local machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_features_pdf.to_csv(\"./Word2Vec-Features.csv\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "dbconnect",
   "language": "python",
   "name": "dbconnect"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
